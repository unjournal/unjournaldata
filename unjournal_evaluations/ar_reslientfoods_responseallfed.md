---
article:
  doi: 10.21428/d28e8e57.009af92d
  elocation-id: responseallfed
author:
- David Denkenberger
- Anders Sandberg
- Ross John Tieman
- Joshua M. Pearce
bibliography: /tmp/tmp-60pb8Q11hZ7nxG.json
copyright:
  link: "https://creativecommons.org/licenses/by/4.0/"
  text: Creative Commons Attribution 4.0 International License
  type: CC-BY
csl: /app/dist/server/server/utils/citations/citeStyles/apa-6th-edition.csl
date:
  day: 12
  month: 05
  year: 2023
journal:
  publisher-name: The Unjournal
  title: The Unjournal
link-citations: true
title: Authors' response to Unjournal evaluations of "Long term
  cost-effectiveness of resilient foods for global catastrophes compared
  to artificial general intelligence"
uri: "https://unjournal.pubpub.org/pub/responseallfed"
---

This is a response to the evaluation of Denkenberger et al
[@temp_id_927774568152955].

# Response to *Unjournal* Reviewer Reports on *International Journal of Disaster Risk Reduction* (May 2022) Vol. 73. {#response-to-unjournal-reviewer-reports-on-international-journal-of-disaster-risk-reduction-may-2022-vol-73}

David Denkenberger

Anders Sandberg

Ross John Tieman

Joshua M. Pearce

To start with we would like to commend the format and reviewer comments
which were of extremely high quality. The evaluations provided well
thought out and constructively critical analysis of the work, pointing
out several assumptions which could impact findings of the paper while
also recognizing the value of the work in spite of some of these
assumptions. Research in this space is difficult due to the highly
interdisciplinary nature of the questions being asked, and the major
uncertainties that need to be addressed. We value good epistemics and
understand that it takes many people critically looking at a problem to
achieve this, which is what motivated our participation in the Unjournal
pilot. A format which allows work to be published and reviewed in an
open nuanced manner can reduce the friction of working on such questions
and speed up communal sense making on important questions. We are
excited to have participated and look forward to seeing how Unjournal
progresses. We hope that future work highlighted by the reviewers that
addresses assumptions and issues of the paper will be undertaken, by
external parties who are better equipped to critically analyse this area
of research improving epistemics in relation to nuclear risk, resilient
foods, AGI safety and the greater the existential risk space.

To clarify, the intention of the comparison of resilient foods to AGI
safety was chosen as AGI safety is considered the greatest x-risk by
many. Consequently, comparison of cost-effectiveness of resilient foods
to AGI safety was intended to highlight the merit of resilient foods to
motivate further investment, as opposed to motivating redirecting
funding from AGI safety to resilient foods.

We have included responses to aspects of the evaluations below.

### **Evaluation 1**

**Structure of cost-effectiveness argument**

> -   The biggest issue with interpretability this causes is that I
>     struggle to understand what features of the analysis are making
>     resilient food appear cost-effective because of some feature of
>     resilient food, and which are making resilient food appear
>     cost-effective because of some feature of AI. The methods used by
>     the authors mean that a mediocre case for resilient food could be
>     made to look highly cost-effective with an exceptionally poor case
>     for AI, since their central result is the multiplier of value on a
>     marginally invested dollar for resilient food vs AI. This is
>     important, because the authors' argument is that resilient food
>     should be funded because it is more effective than AI Risk
>     management, but this is motivated by AI Risk proponents agreeing
>     AI Risk is important -- in scenarios where AI Risk is not worth
>     investing in then this assumption is broken and cost effectiveness
>     analysis against a 'do nothing' alternative is required. For
>     example, the authors do not investigate scenarios where the
>     benefit of the intervention in the future is negative because
>     "negative impacts would be possible for both resilient foods and
>     AGI safety and there is no obvious reason why either would be more
>     affected". While this is potentially reasonable on a mathematical
>     level, it does mean that it would be perfectly possible for
>     resilient foods to be net harmful and the paper not correctly
>     identify that funding them is a bad idea -- simply because funding
>     AI Risk reduction is an even *worse* idea, and this is the only
>     given alternative. If the authors want to compare AGI risk
>     mitigation and resilient foods against each other without a 'do
>     nothing' common comparator (which I do not think is a good idea),
>     they must at the very least do more to establish that the results
>     of their AI Risk model map closely to the results which cause the
>     AI Risk community to fund AI Risk mitigation so much. As this is
>     not done in the paper, a major issue of interpretability is
>     generated.

We could have compared to the Open Philanthropy last dollar if that had
been available at the time of publishing (\$200 trillion per world saved
or 0.05 basis points of existential risk per \$billion):
<https://forum.effectivealtruism.org/posts/NbWeRmEsBEknNHqZP/longterm-cost-effectiveness-of-founders-pledge-s-climate>.
Our median for spending \$100 million is \~2x10\^-10 far future
potential increase per dollar, or 500 basis points per \$billion, or
\~10,000 times as cost-effective. Ours is about 500 times as cost
effective as the upper bound on that page.

> -   More generally, this causes the authors to have to write up their
>     results in a non-natural fashion. As an example of the sort of
>     issues this causes, conclusions are expressed in entirely
>     non-natural units in places ("Ratio of resilient foods mean cost
>     effectiveness to AGI safety mean cost effectiveness" given \$100m
>     spend), rather than units which would be more natural
>     ("Cost-effectiveness of funding resilient food development"). I
>     cannot find expressed anywhere in the paper a simple table with
>     the average costs and benefits of the two interventions, although
>     a reference is made to Denkenberger & Pearce
>     [@temp_id_536922568096887] where these values were presented for
>     near-term investment in resilient food. This makes it extremely
>     hard for a reader to draw sensible policy conclusions from the
>     paper unless they are already an expert in AGI risk and so have an
>     intuitive sense of what an intervention which is '3-6 times more
>     cost-effective than AGI risk reduction' looks like. The paper
>     might be improved by the authors communicating summary statistics
>     in a more straightforward fashion.

Figure 5 is Far future potential increase per \$, which is an absolute
value. That said, we acknowledge that the presentation of findings
throughout could have been made more straightforward for non-expert
readers and will aim to communicate summary statistics in a more
accessible way in future work.

> Continuing on from this point, I don't understand the conceptual
> framework that has the authors consider the value of invested dollars
> in resilient food at the margin. The authors' model of the value of an
> invested dollar is an assumption that it is distributed
> logarithmically. Since the entire premise of the paper hinges on the
> reasonability of this argument, it is very surprising there is no
> sensitivity analysis considering different distributions of the
> relationship between intervention funding and value. Nevertheless, I
> am also confused as to the model even on the terms the authors
> describe; the authors' model appears to be that there is some sort of
> 'invention' step where the resilient food is created and discovered
> (this is mostly consistent with Denkenberger & Pearce
> [@temp_id_536922568096887], and is the only interpretation consistent
> with the question asked in the survey). In which case, the marginal
> value of the first invested dollar is zero because the 'invention' of
> the food is almost a discrete and binary step. The marginal value per
> dollar continues to be zero until the 86 millionth dollar, where the
> marginal value is the entire value of the resilient food in its
> entirety. There seems to be no reason to consider the marginal dollar
> value of investment when a structural assumption made by the authors
> is that there is a specific level of funding which entirely saturates
> the field, and this would make presenting results significantly more
> straightforward -- it is highly nonstandard to use marginal dollars as
> the unit of cost in a cost-effectiveness analysis, and indeed is so
> nonstandard I'm not certain fundamental assumptions of
> cost-effectiveness analysis still hold.

In the survey, we ask about the job of spending \$100 million, but then
we refer to the cost per life saved paper which discusses separate
interventions of research, planning, and piloting, some of these
interventions such as early stage research don\'t cost very much money
and increase the probability of success, which is why we argue marginal
thinking makes sense. For instance, significant progress in the last
year in prioritizing the most cost-effective resilient foods that also
feed a lot of people has been achieved, this could lead to development
and deployment of much more effective food production methods for such
scenarios.

**Methods**

> The presentation of the sensitivity analysis as 'number of parameters
> needed to flip' is nonstandard, but a clever way to intuitively
> express the level of confidence the authors have in their conclusions.
> Although clever, I am uncertain if the approach is appropriately
> implemented; the authors limit themselves to the 95% CI for their
> definition of an 'unfavourable' parameter, and I think this approach
> hides massive structural uncertainty with the model. For example, in
> Table 5 the authors suggest their results would only change if the
> probability of nuclear war per year was 4.8x10\^-5 (plus some other
> variables changing) rather than their estimated of 7x10\^-3
> (incidentally, I think the values for S model and E model are switched
> in Table 5 -- the value for pr(nuclear war) in the table's S model
> column corresponds to the probability given in the E model).

This appears to be a coincidence, the lowest 5th percentile value of all
nuclear war probabilities was used, which was given by the furthest year
into the future with no nuclear war. For S model this is 49 years into
the future and has a value of 4.8x10\^-5 and for E model this is 149
years into the future and has a value of 1.8X10\^-4 (see inserted
screenshots).

*S model 5th percentile of nuclear war probability per year after x
years of no nuclear war (lowest probability of nuclear war per year
after 49 years no nuclear war)*: [Figure
link](https://drive.google.com/file/d/19-fHLqVU-IVpssFaydYATQmaXWcRJGwz/view "null")

*E model 5th percentile of nuclear war probability per year after x
years of no nuclear war (lowest probability of nuclear war per year
after 149 years no nuclear war)*: [Figure
link](https://drive.google.com/file/d/17aJoUH3KLE22sOIhkRTZc9lq5zvoYq7C/view "null")

> Third, the authors could have done more to make it clear that the
> 'Expert Model' was effectively just another survey with an n of 1.
> Professor Sandburg, who populated the Expert Model, is also an author
> on this paper and so it is unclear what if any validation of the
> Expert Model could reasonably have been undertaken -- the E model is
> therefore likely to suffer from the same drawbacks as the S model. It
> is also unclear if Professor Sandburg knew the results of the S Model
> before parameterising his E Model -- although this seems highly likely
> given that 25% of the survey's respondents were Professor Sandburg's
> co-authors. This could be a major source of bias, since presumably the
> authors would prefer the two models to agree and the expert
> parameterising the model is a co-author.

Professor Sandberg was not shown the S model parameters to avoid
introducing bias. That said, we acknowledge that the small size of the
existential risk field, and influence of several highly cited early
works such as the[ FHI TECHNICAL REPORT Global Catastrophic Risks
Survey](https://www.fhi.ox.ac.uk/reports/2008-1.pdf "null") have the
potential to introduce anchoring bias.

**Parameter estimates**

> Notwithstanding my concerns about the use of the survey instrument, I
> have some object level concerns with specific parameters described in
> the model.
>
> -   The discount rate for both costs and benefits appears to be zero,
>     which is very nonstandard in economic evaluation. Although the
>     authors make reference to "long termism, the view that the future
>     should have a near zero discount rate", the reference for this
>     position leads to a claim that a zero rate of *pure time
>     preference* is common, and a footnote observing that "the
>     consensus against discounting future well-being is not universal".
>     To be clear, pure time preference is only one component of a
>     well-constructed discount rate and therefore a discount rate
>     should still be applied for costs, and probably for future
>     benefits too. Even notwithstanding that I think this is an error
>     of understanding, it is a limitation of the paper that discount
>     rates were not explored, given they seem very likely to have a
>     major impact on conclusions.

Thank you for highlighting this point, this is an important
consideration that would make valuable future work.

> -   A second concern I have relating to parameterisation is the
>     conceptual model leading to the authors' proposed costing for the
>     intervention. The authors explain their conceptual model linking
>     nuclear war risk to agricultural decline commendably clearly, and
>     this expands on the already strong argument in Denkenberger &
>     Pearce [@temp_id_536922568096887] . However, I am less clear on
>     their conceptual model linking approximately \$86m of research to
>     the widescale post-nuclear deployment of resilient foods. The
>     assumption seems to be (and I stress this is my assumption based
>     on Denkenberger & Pearce [@temp_id_536922568096887] -- it would
>     help if the authors could make it explicit) that \$86m purchases
>     the 'invention' of the resilient food, and once the food is
>     'invented' then it can be deployed when needed with only a little
>     bit of ongoing training (covered by the \$86m). This seems to me
>     to be an optimistic assumption; there seems to be no cost
>     associated with disseminating the knowledge, or any raw materials
>     necessary to culture the resilient food. Moreover, the model seems
>     to structurally assume that distribution chains survive the
>     nuclear exchange with 100% certainty (or that the materials are
>     disseminated to every household which would increase costs), and
>     that an existing resilient food pipeline exists at the moment of
>     nuclear exchange which can smoothly take over from the
>     non-resilient food pipeline.

Denkenberger & Pearce [@temp_id_536922568096887] does not include costs
post GCR and only considers R&D, and response and preparedness planning,
and related costs pre disaster. This work pre disaster would likely
result in expenditure post disaster being significantly lower than
stored food.

> I have extremely serious reservations about these points. I think it
> is fair to say that an economics paper which projected benefits as far
> into the future as the authors do here without an exploration of
> discount rates would be automatically rejected by most editors, and it
> is not clear why the standard should be so different for existential
> risk analysis. A cost of \$86m to mitigate approximately 40% of the
> impact of a full-scale nuclear war between the US and a peer country
> seems *prima facie* absurd, and the level of exploration of such an
> important parameter is simply not in line with best practice in a
> cost-effectiveness analysis (especially since this is the parameter on
> which we might expect the authors to be least expert). I wouldn't want
> my reservations about these two points to detract from the very good
> and careful scholarship elsewhere in the paper, but neither do I want
> to give the impression that these are just minor technical details --
> these issues could potentially reverse the authors' conclusions, and
> should have been substantially defended in the text.

We agree that this estimate from the published work is likely low and
have since updated our view on cost upwards. The nuclear war probability
utilized does not include other sources of nuclear risk such as
accidental detonation of nuclear weapons leading to escalation,
intentional attack, or dyads involving China.

### **Evaluation 2**

> The Methods section is well organised and documented, but once in a
> while it lacks clarity and it uses terminology that may or may not be
> appropriate. Here's a list of things Ii found a bit confusing:
>
> -   Terminology
>
>     -   The submodels for food and AGI are said to be "independent";
>         is this meant in a probabilistic way? Are there no hidden/not
>         modelled variables that influence both?

In reality we anticipate that there are a myriad of ways in which
nuclear risk and AGI would interact with one another. Are AI systems
implemented in nuclear command and control? If so when and how does this
change nuclear war probability? What will data sets used to train AI
systems post nuclear exchange look like compared to present? Post
nuclear exchange will there be greater pressure to utilize autonomous
systems? How many/which chip fabs will be destroyed during a nuclear
exchange?

Capturing such interactions in the model in a rigorous way would have
required a considerable section within the paper, which was beyond the
scope of what could be included. We raised that the submodels are
independent to make people aware of this simplifying assumption.

We believe that investigating the interdependence of x-risks is an
important open question that would make valuable future work.

> -   The "expert" model was quite confusing for me, maybe because
>     "Sandberg" and the reference number after "Sandberg" don't match,
>     or maybe because I was expecting a survey vs. expert judgement
>     quantification of uncertainty. As I said (structured) expert
>     judgement is one of my interests:
>     <https://link.springer.com/book/10.1007/978-3-030-46474-5>

There is an error in the referencing, this should have linked to the
following guesstimate model: Denkenberger, D., Sandberg, A.,
Cotton-Barrat, O., Dewey, D., & Li, S (2019b). Food without the sun and
AI X risk cost effectiveness general far future impact publication.
Guesstimate. <https://www.getguesstimate.com/models/11691>

> -   In the caption of fig 2, "index nodes" and "variable nodes" are
>     introduced. Index nodes are later described, but I don\'t think I
>     understood what was meant by "variable" nodes. Aren't all
>     probabilistic nodes variable?

This language comes from analytica taxonomies of the different types of
nodes, this is simply describing what the nodes are in the analytica
implementation. See this link for more information:
<https://docs.analytica.com/index.php/Create_and_edit_nodes>

> -   Underlying assumptions/definitions
>
>     -   The structure of the models is not discussed. How did you
>         decide that this is a robust structure (no sensitivity to
>         structure performed as far as I understood)

An earlier model only considered collapse and nonrecovery of
civilization as the route to far future impact. The current structure
developed the structure further and is more inclusive.

> -   What is meant by "the data from surveys was used directly instead
>     of constructing continuous distributions"?

Instead of sampling from a distribution created from the survey data,
the model randomly draws a survey response value from the index of
values for each of the 32000 model runs.

> It is great that the models are available upon request, but it would
> be even better if they would be public so the computational
> reproducibility could be evaluated as well.

Links to the models are available at the following links.

S-model: <https://www.getguesstimate.com/models/13082>

E-model: <https://www.getguesstimate.com/models/11691>
