---
article:
  doi: 10.21428/d28e8e57.480a4d04
  elocation-id: welfarenudgesevalsum
author:
- Evaluator 1
- Evaluator 2
- Florian Habermacher
- David Reinstein
bibliography: /tmp/tmp-526l9vIQU5hB7V.json
copyright:
  link: "https://creativecommons.org/licenses/by/4.0/"
  text: Creative Commons Attribution 4.0 International License
  type: CC-BY
csl: /app/dist/server/server/utils/citations/citeStyles/apa-6th-edition.csl
date:
  day: 15
  month: 05
  year: 2024
journal:
  publisher-name: The Unjournal
  title: The Unjournal
link-citations: true
title: "Evaluation Summary and Metrics: \"When do\"Nudges\" Increase
  Welfare?\""
uri: "https://unjournal.pubpub.org/pub/welfarenudgesevalsum"
---

# Abstract 

We organized two evaluations of the paper: \"When do \"Nudges\" Increase
Welfare?\"[@temp_id_06659697377391827].[^1] The evaluators agree that
the paper provides a novel, valuable contribution to the understanding
of how nudges impact welfare in equilibrium. They acknowledge the
paper's substantive theoretical modeling and its tentative empirical
validation. Nonetheless, they highlight several limitations. To read
these evaluations, please see the links below.

This paper was selected as part of our[ (NBER) direct evaluation
track](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/considering-projects/direct-evaluation-track "null").

## **Evaluations**

[Anonymous Evaluation
1](https://unjournal.pubpub.org/pub/welfarenudgese1 "null")

[Anonymous Evaluation
2](https://unjournal.pubpub.org/pub/welfarenudgese2 "null")

# **Overall ratings**

We asked evaluators to provide overall assessments as well as ratings
for a range of specific criteria. * *

**I. Overall assessment: **We asked them to rank this paper
"heuristically" as a percentile "relative to all serious research in the
same area that you have encountered in the last three years." We
requested they "consider all aspects of quality, credibility, importance
to knowledge production, and importance to practice."

**II. Journal rank tier, normative rating (0-5):**[^2]** **On a 'scale
of journals', what 'quality of journal' should this be published in?
(See ranking tiers discussed
[here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers "null").)
*Note: 0= lowest/none, 5= highest/best.*

+-----------------+-------------------+---+
|                 | **Overall         | * |
|                 | assessment        | * |
|                 | (0-100)**         | J |
|                 |                   | o |
|                 |                   | u |
|                 |                   | r |
|                 |                   | n |
|                 |                   | a |
|                 |                   | l |
|                 |                   | r |
|                 |                   | a |
|                 |                   | n |
|                 |                   | k |
|                 |                   | t |
|                 |                   | i |
|                 |                   | e |
|                 |                   | r |
|                 |                   | , |
|                 |                   | n |
|                 |                   | o |
|                 |                   | r |
|                 |                   | m |
|                 |                   | a |
|                 |                   | t |
|                 |                   | i |
|                 |                   | v |
|                 |                   | e |
|                 |                   | r |
|                 |                   | a |
|                 |                   | t |
|                 |                   | i |
|                 |                   | n |
|                 |                   | g |
|                 |                   | ( |
|                 |                   | 0 |
|                 |                   | - |
|                 |                   | 5 |
|                 |                   | ) |
|                 |                   | * |
|                 |                   | * |
+=================+===================+===+
| Anon. Evaluator | 85                | 4 |
| 1               |                   | . |
|                 |                   | 0 |
+-----------------+-------------------+---+
| Anon. Evaluator | 86                | 3 |
| 2               |                   | . |
|                 |                   | 7 |
+-----------------+-------------------+---+

*See
"*[*Metrics*](https://unjournal.pubpub.org/pub/welfarenudgesevalsum#metrics "null")*"
below for a more detailed breakdown of the evaluators' ratings across
several categories. To see these ratings in the context of all Unjournal
ratings, with some analysis, see our *[*data presentation
here.*](https://unjournal.github.io/unjournaldata/chapters/evaluation_data_analysis.html#basic-presentation "null")[^3]*
*

*See
*[*here*](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#metrics-overall-assessment-categories "null")*
for the current full evaluator guidelines, including further explanation
of the requested ratings.*[^4]

# Evaluation summaries

## Anonymous evaluator 1

The present paper reports on nudges failing to improve utilitarian
welfare because they increase higher-order choice distortions. While the
paper is highly complex in practically all regards, their general idea
is important for public policy. The welfare losses implied by nudges may
not be large, and real-life policymaking emphatically does not proceed
by maximizing utilitarian welfare, but this paper could represent a step
forward in how we think about policy incidence over the whole
distribution of behaviors.

## Anonymous evaluator 2

This is a very strong and interesting paper. More consideration of the
welfare impacts of nudges is to be welcomed, and there is clearly a gap
in the market for considering heterogeneous effects. However, there are
concerns about whether or not the experimental method is really designed
to answer questions of this type.

# Metrics

## Ratings

[See
here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#quantitative-metrics "null")
for details on the categories below, and the guidance given to
evaluators.

+----------------------------------+-----------------+--------+----------+---------------+--------+
|                                  | **Evaluator 1** |        |          | **Evaluator   |        |
|                                  |                 |        |          | 2**           |        |
|                                  | Anonymous       |        |          |               |        |
|                                  |                 |        |          | Anonymous     |        |
+==================================+=================+========+==========+===============+========+
| **Rating category**              | **Rating        | **90%  | **Co     | **Rating      | **90%  |
|                                  | (0-100)**       | CI **  | mments** | (0-100)**     | CI **  |
|                                  |                 |        |          |               |        |
|                                  |                 | **(0-  |          |               | **(0-  |
|                                  |                 | 100)\* |          |               | 100)\* |
|                                  |                 | **     |          |               | **     |
+----------------------------------+-----------------+--------+----------+---------------+--------+
| Overall assessment[^5]           | 85              | (70,   | [^6]     | 86            | (76,   |
|                                  |                 | 95)    |          |               | 96)    |
+----------------------------------+-----------------+--------+----------+---------------+--------+
| Advancing knowledge and          | 15              | (10,   | [^8]     | 50            | (45,   |
| practice[^7]                     |                 | 20)    |          |               | 55)    |
+----------------------------------+-----------------+--------+----------+---------------+--------+
| Methods: Justification,          | 80              | (50,   | [^10]    | 75            | (66,   |
| reasonableness, validity,        |                 | 90)    |          |               | 84)    |
| robustness[^9]                   |                 |        |          |               |        |
+----------------------------------+-----------------+--------+----------+---------------+--------+
| Logic & communication[^11]       | 85              | (75,   | [^12]    | 70            | (66,   |
|                                  |                 | 90)    |          |               | 74)    |
+----------------------------------+-----------------+--------+----------+---------------+--------+
| Open, collaborative,             | 95              | (90,   | [^14]    | 97            | (93,   |
| replicable[^13]                  |                 | 100)   |          |               | 100)   |
+----------------------------------+-----------------+--------+----------+---------------+--------+
| Real-world relevance [^15]       | 15              | (10,   | [^16]    | 24            | (17,   |
|                                  |                 | 20)    |          |               | 32)    |
+----------------------------------+-----------------+--------+----------+---------------+--------+
| Relevance to global              | 15              | (10,   | [^18]    | 10            | (1,    |
| priorities[^17]                  |                 | 20)    |          |               | 20)    |
+----------------------------------+-----------------+--------+----------+---------------+--------+

## Journal ranking tiers

[See
here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers "null")
for more details on these tiers.

+-------------------------------+-------------+--------+-----------+---------+
|                               | **Evaluator |        | **        |         |
|                               | 1**         |        | Evaluator |         |
|                               |             |        | 2**       |         |
|                               | Anonymous   |        |           |         |
|                               |             |        | Anonymous |         |
+===============================+=============+========+===========+=========+
| **Judgment**                  | **Ranking   | **90%  | **Ranking | **90%   |
|                               | tier        | CI **  | tier      | CI **   |
|                               | (0-5)**     |        | (0-5)**   |         |
+-------------------------------+-------------+--------+-----------+---------+
| On a 'scale of journals',     | 4.0         | (3.5,  | 3.7       | (3.3,   |
| what 'quality of journal'     |             | 4.2)   |           | 4.1)    |
| *should* this be published    |             |        |           |         |
| in?                           |             |        |           |         |
+-------------------------------+-------------+--------+-----------+---------+
| What 'quality journal' do you | 4.0         | (4.0,  | 4.4       | (4.0,   |
| expect this work *will* be    |             | 5.0)   |           | 4.9)    |
| published in?                 |             |        |           |         |
+-------------------------------+-------------+--------+-----------+---------+
| [See                          | *We         |        |           |         |
| here](https://                | summarize   |        |           |         |
| globalimpact.gitbook.io/the-u | these as:*  |        |           |         |
| njournal-project-and-communic |             |        |           |         |
| ation-space/policies-projects | -   0.0:    |        |           |         |
| -evaluation-workflow/evaluati |             |        |           |         |
| on/guidelines-for-evaluators# |  Marginally |        |           |         |
| journal-ranking-tiers "null") |     respect |        |           |         |
| for more details on these     | able/Little |        |           |         |
| tiers.                        |     to no   |        |           |         |
|                               |     value   |        |           |         |
|                               |             |        |           |         |
|                               | -   1.0:    |        |           |         |
|                               |             |        |           |         |
|                               | OK/Somewhat |        |           |         |
|                               |             |        |           |         |
|                               |    valuable |        |           |         |
|                               |             |        |           |         |
|                               | -   2.0:    |        |           |         |
|                               |             |        |           |         |
|                               |    Marginal |        |           |         |
|                               |     B-jou   |        |           |         |
|                               | rnal/Decent |        |           |         |
|                               |     field   |        |           |         |
|                               |     journal |        |           |         |
|                               |             |        |           |         |
|                               | -   3.0:    |        |           |         |
|                               |     Top     |        |           |         |
|                               |     B-jou   |        |           |         |
|                               | rnal/Strong |        |           |         |
|                               |     field   |        |           |         |
|                               |     journal |        |           |         |
|                               |             |        |           |         |
|                               | -   4.0:    |        |           |         |
|                               |             |        |           |         |
|                               |    Marginal |        |           |         |
|                               |     A-      |        |           |         |
|                               | Journal/Top |        |           |         |
|                               |     field   |        |           |         |
|                               |     journal |        |           |         |
|                               |             |        |           |         |
|                               | -   5.0:    |        |           |         |
|                               |     A-      |        |           |         |
|                               | journal/Top |        |           |         |
|                               |     journal |        |           |         |
+-------------------------------+-------------+--------+-----------+---------+

#  {#r6368766935}

# Evaluation manager's discussion

The two evaluations underscore the paper's important theoretical
contributions, formally highlighting and experimentally underlining the
role that (nudge) treatment effect heterogeneity plays, in contrast to
traditional welfare analysis focusing on changes in average outcomes.
Even if nudges cause average behavior to move in the desired
welfare-improving direction, they might lead to greater variance in
distortions across individuals, which could lead to net welfare losses.
In addition to the impacts through the 'variance' channel, the authors'
analysis highlights the importance of (i) the supply side with market
power, where firms adjust price in response to changes in demand, and of
(ii) considering the presence of distortion-correcting taxation. Both of
these tend to reduce the average effect of nudges in equilibrium
(considering the tax and pricing responses) so that the nudge's effects
on variance more easily dominate. 

The evaluators agree that the paper provides a novel, valuable
contribution to the understanding of how nudges impact welfare in
equilibrium. They acknowledge the paper's substantive theoretical
modeling and its tentative empirical validation. Nonetheless, they
highlight several limitations.

Evaluator 1 found the presentation difficult and suggested more
directness, clarity, and simpler terminology.

Both evaluators raised concerns about the experimental methods. At least
one of the experiments (fuel efficiency) involved a rather complex
choice task in an unfamiliar, hypothetical situation (the value of a car
if gasoline *did not matter*). In one experiment, the incentives seemed
rather weak (buying a beverage to be delivered with ⅕ probability). 

'Research degrees of freedom' was also highlighted, with one evaluator
noting some author discretion in dropping "outlying" observations. This
raised questions about the reliability of the experiments' main results.
This may be of concern as some of their estimates finding a welfare loss
(see their Table 2) appeared statistically and economically
insignificant (or marginally significant). 

Another lingering concern (largely from one of our evaluation managers):
"How relevant is this to typical domains of interest?" Is it plausible
in practice that the highlighted (negative) effect of increasing
variance could *dominate* the desired effect of the nudge on average
behavior? In many cases, nudges may be used where taxation is
impractical or politically infeasible. For a case with little or no
distortion-correcting taxation, for welfare to be reduced in net, a high
enough share of people have to *overreact *in the nudge's desired
direction. In addition to the cases used in the experiment--car fuel
efficiency and sugary drinks--the authors cite nudge policies aiming at
increasing retirement savings, healthy eating, exercise, environmental
conservation, and organ donation. Is it plausible that nudges would
compel large shares of the population to save for their retirement, to
eat healthily, to exercise, to protect the environment*,* or to donate
organs* too much *relative to their own (or social) interest? For some
of these domains it seems unlikely that many people will be 'overnudged'
so a focus on the *average* effects of nudging may be reasonable.

# Unjournal process 

## Note: Paper updates, versions considered

Each evaluator considered the most recent NBER or non-NBER version of
the paper available at the time of their evaluation: Evaluator 1
considered the 20 Sep 2023 version of the working paper, and Evaluator 2
considered the April 2024 version of the [NBER Working Paper 30740 When
do \"Nudges\" Increase
Welfare?](https://www.nber.org/papers/w30740 "null").

In May 2024, a newer version was published on NBER that addressed at
least one concern raised in earlier evaluations---the use of the term
\'non-standard policy instrument\' (NPI)---as noted by the authors.

## Why we chose this paper 

We chose this paper because nudges are widely used, including in
impactful areas like global health and managing pandemics (see e.g.,[
this Guardian
article](https://www.theguardian.com/global-development-professionals-network/2016/mar/04/world-bank-nudging-attitudes-health-hygiene "null")),
and understanding their effects on welfare is important. The paper\'s
findings may affect how policies are considered in the context of the
emergence of public sector 'nudge units' as well as animportant pushback
against the 'nudge agenda'. The importance and potential impact of the
paper suggested that a thorough evaluation could provide valuable
insights into both the theoretical framework and the credibility of the
experiments as a source of evidence.

## How we chose the evaluators

We looked for evaluators with:

1.  an applied understanding of public finance/public econ. theory,
    considering normative issues

2.  experience considering the value of framed choice experiments and
    elicitations like this, and how generalizable they are to real-world
    markets of interest.

## Evaluation process: Suggestions

We suggested to evaluators that they might consider some of the issues
below

1.  Is a model in which government adjusts taxes/subsidies optimally a
    relevant one for this discussion? Do their arguments meaningfully
    carry over to a more general environment?

    -   We had a question regarding the relevance of a model where there
        is zero (or low) pass-through. And to put it very explicitly:
        Don't we think of nudges usually exactly in places where we have
        reason to believe behavior *can *have an impact, and where we
        see *no other easy way* to steer people in the right direction,
        e.g., as adequate taxes are politically infeasible?!

2.  "Welfare also depends on whether the NPI reduces the variance of
    distortions from heterogenous biases and externalities, and the
    average effect becomes irrelevant with zero pass-through or optimal
    taxes."

    -   Is this main argument correct, are there flaws in it, is it
        robust to relevant small modifications in the theoretical model?

3.  "We apply our framework to randomized experiments evaluating
    automotive fuel economy labels and sugary drink health labels \..."
    These experiments were run on a particular pool of participants,
    asking questions about particular contexts.

    -   Are the inferences made from these participants in this context
        meaningful? Does the experiment itself add any 'value of
        information'? I.e., do we know more about something important in
        the real world, adjusting or concentrating our beliefs, after
        having seen the results of the experiment

    -   -(If so) do the results in this context meaningfully generalize
        in ways that will help inform (globally) important real-world
        policies?  

4.  There were some real incentives to choose according to one's true
    preferences (in the drinks case?) or to get state WTP 'correctly' as
    imputed from their earlier survey responses (in the autos case).  

    -   Were these incentives strong, meaningful, and correctly aligned?

5.  Statistical modeling of the results, statistical inferences,
    structure of any structural model used to derive welfare
    implications; consistency with pre-registration/pre-analysis plan

## Author engagement

We reached out to the authors on Feb. 2, 2024 to let them know we were
evaluating their paper, asking them about updated versions, or other
concerns. They did not respond at this time. We notified them again on
May 3, sharing the evaluations. They responded on May 9, noting that
they did not have the bandwidth to provide a detailed response. They let
us know about a version that had been released on NBER in the last few
days, noting that it clarified some of the issues the evaluators had
raised.

# References

[@niep8youia1] Allcott, Hunt, Daniel Cohen, William Morrison, and Dmitry
Taubinsky. 2022. *When Do 'Nudges' Increase Welfare?* With National
Bureau of Economic Research. NBER Working Paper Series, no. w30740.
National Bureau of Economic Research.

**Published Paper: **Allcott, Hunt, Daniel Cohen, William Morrison, and
Dmitry Taubinsky. 2025. \"When Do \"Nudges\" Increase Welfare?\"
*American Economic Review* 115 (5): 1555--96**. **DOI:
10.1257/aer.20231304

[^1]: Each evaluator considered the most recent NBER or non-NBER version
    of the paper available at the time of their evaluation. See "Note:
    Paper updates, versions considered" below.

[^2]: See "1 Mar 2024 note" above.

[^3]: Note: if you are reading this before, or soon after this has been
    publicly released, the ratings from this paper may not yet have been
    incorporated into that data presentation.

[^4]: See "1 Mar 2024 note" above. See
    [here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators/why-these-guidelines#adjustments-to-metrics-and-guidelines-previous-presentations)
    to learn how this changed, and to see the earlier instructions.

[^5]: Judge the quality of the research heuristically. Consider all
    aspects of quality, credibility, importance to knowledge production,
    and importance to practice.

[^6]: The theoretical analysis has very high quality. The experiments
    could be improved so that they are clearer to subjects. The
    econometric analysis is state-of-the art, albeit highly complex and
    thus potentially less robust.

[^7]: To what extent does the project contribute to the field or to
    practice, particularly in ways that are directly or indirectly
    relevant to global priorities and impactful interventions?

[^8]: Since this project does not consider real-life policymaking, its
    impact for global priorities is severely limited. Nonetheless, they
    highlight challenges even under utilitarianism as a motivation of
    policymakers.

[^9]: Are methods clearly justified and explained? Are methods and their
    underlying assumptions reasonable? Are the results likely to be
    robust to changes in the assumptions? Have the authors avoided bias
    and questionable research practices?

[^10]: The methods appear to be appropriate; the experiment is simple
    enough, albeit with some issues. I am not an econometrician and thus
    unable to judge the intricacies of the highly complex mixed effects
    model or their implementation. However, the general approach appears
    legitimate.

[^11]: Are concepts clearly defined? Is the reasoning transparent? Are
    conclusions consistent with the evidence (or formal proofs)
    presented? Are the data and/or analysis, including tables and
    figures, relevant to the argument?

[^12]: Theory-wise, everything is clear to me. Regarding the analyses,
    tables and figures certainly help, and all concepts are generally
    clear enough. Nonetheless, all aspects of this project are highly
    complex and the paper could benefit from more clarity. But this does
    not invalidate the logic. Regarding statistical analyses: it may be
    that there is a better way to do them, but I do not know of such a
    way.

[^13]: Would another researcher be able to replicate the analysis? Are
    the method and its details explained sufficiently? Is the source of
    the data clear? Is the data made as widely available as possible,
    with clear labeling and explanation? Do the authors provide
    resources that are likely to enable future research and
    meta-analysis?

[^14]: Replication package provided (correct URL is in version
    evaluated), both analyses and experiment are highly replicable.

[^15]: Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic and relevant to practitioners?

[^16]: See answer to \"Advancing knowledge and practice\"; the authors
    miss the true motivations of policymakers, who after all do not
    maximize utilitarian welfare.

[^17]: Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?

[^18]: See answer to \"Advancing knowledge and practice\"
