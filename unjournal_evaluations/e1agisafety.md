---
article:
  elocation-id: e1agisafety
author:
- Evaluator 1
bibliography: /tmp/tmp-59xCn7fqkeGCfX.json
copyright:
  link: "https://creativecommons.org/licenses/by/4.0/"
  text: Creative Commons Attribution 4.0 International License
  type: CC-BY
csl: /app/dist/server/server/utils/citations/citeStyles/apa-6th-edition.csl
date:
  day: 03
  month: 06
  year: 2025
journal:
  publisher-name: The Unjournal
  title: The Unjournal
link-citations: true
title: "Evaluation 1 of \"Towards best practices in AGI safety and
  governance: A survey of expert opinion\""
uri: "https://unjournal.pubpub.org/pub/e1agisafety"
---

# Abstract 

This insightful and policy-relevant paper brings empirical grounding to
AGI safety measures by assessing expert consensus. It finds broad
support for nearly all proposed safety practices across AGI labs,
governments, and civil society. Key limitations \[of the paper\] include
potential sampling bias -- particularly over-representation of
safety-minded respondents -- and the challenge of interpreting abstract
agreement as indicative of real-world implementation. Still, the study
offers valuable input for policymakers and contributes meaningfully to
discussions on AGI safety.

# Summary Measures

We asked evaluators to give some overall assessments, in addition to
ratings across a range of criteria. *See the *[*evaluation summary
"metrics"*](https://unjournal.pubpub.org/pub/evalsumagisafety#metrics "null")*
for a more detailed breakdown of this. See these ratings in the context
of all Unjournal ratings, with some analysis, in our *[*data
presentation
here.*](https://unjournal.github.io/unjournaldata/chapters/evaluation_data_analysis.html#basic-presentation "null")[^1]*
*

+-------------------+-------------------+---+
|                   | **Rating**        | * |
|                   |                   | * |
|                   |                   | 9 |
|                   |                   | 0 |
|                   |                   | % |
|                   |                   | C |
|                   |                   | r |
|                   |                   | e |
|                   |                   | d |
|                   |                   | i |
|                   |                   | b |
|                   |                   | l |
|                   |                   | e |
|                   |                   | I |
|                   |                   | n |
|                   |                   | t |
|                   |                   | e |
|                   |                   | r |
|                   |                   | v |
|                   |                   | a |
|                   |                   | l |
|                   |                   | * |
|                   |                   | * |
+===================+===================+===+
| **Overall         | 70/100            | 6 |
| assessment **     |                   | 0 |
|                   |                   |   |
|                   |                   | - |
|                   |                   | 8 |
|                   |                   | 0 |
+-------------------+-------------------+---+
| **Journal rank    | 4.0/5             | 3 |
| tier, normative   |                   | . |
| rating**          |                   | 5 |
|                   |                   |   |
|                   |                   | - |
|                   |                   | 4 |
|                   |                   | . |
|                   |                   | 5 |
+-------------------+-------------------+---+

**Overall assessment **(See footnote[^2])

**Journal rank tier, normative rating (0-5): ** On a 'scale of
journals', what 'quality of journal' should this be published in?[^3]
*Note: 0= lowest/none, 5= highest/best. *

# Claim identification and assessment 

## I. Identify the most important and impactful factual claim this research makes[^4] {#i-identify-the-most-important-and-impactful-factual-claim-this-research-makes}

The most important and impactful claim that this research makes is that
a majority of AGI governance experts exhibit consensus in supporting 49
out of 50 specific safety-related policies and practices. This is
summarized in this statement:

'For every practice but one, the majority of respondents somewhat or
strongly agreed that it should be implemented. Furthermore, for the
average practice on our list, 85.2% somewhat or strongly agreed it
should be implemented.'

## II. To what extent do you \*believe\* the claim you stated above? {#ii-to-what-extent-do-you-believe-the-claim-you-stated-above}

While, as stated above, the paper mainly captures high-level, in
principle agreement with specific safety practices and principles
without actually evaluating trade-offs between these practices and rapid
AGI development, I fully believe the claims presented (over 90%
probability of the claim being true).

# Written report

This paper presents an expert survey on AGI safety and governance
practices, offering empirical grounding for what has so far been a
largely conceptual and normative debate. The authors survey a targeted
sample of 51 experts across AGI labs, academia, government and civil
society, finding high levels of agreement on a wide range of proposed
AGI safety practices. In particular, there is near-unanimous support for
measures such as pre-deployment risk assessments, dangerous capability
evaluations, and third-party model audits - practices that have featured
quite heavily in discussions around AGI safety. The paper\'s findings
are surely of interest to policymakers, standard-setting bodies and
other stakeholders. In addition to documenting the support for these
practices, the paper also discusses the potential role of these norms in
shaping future regulation, contributing to the ongoing debates about how
to operationalize safety measures in the context of increasingly capable
AI systems, which is indeed quite valuable.

The study is methodologically clear, well-organized, and transparent
about its limitations. It begins to fill a critical empirical gap by
mapping the high-level views of domain experts on what responsible AGI
development should look like. That said, there are some important
caveats that should be mentioned. In particular, questions remain about
sampling -- especially whether the sample of respondents is
disproportionately drawn from individuals already aligned with AGI
safety priorities -- and about how to interpret such high levels of
agreement on relatively abstract statements. These caveats don't
undermine the overall value of the paper, but they do suggest that some
care is necessary in interpreting the results as broadly representative,
or in treating consensus on abstract principles as equivalent to
alignment on implementation. These points are discussed in greater
detail below.

## **Major Comments**

### \[Sampling strategy (balance over 'concern for safety')\][^5]

The first concern here relates to the sampling strategy employed. The
authors rightly describe their approach as a purposive sample, selecting
individuals based on their expertise in AGI safety and governance. While
this is an understandable choice given the aims of the paper -- and the
relatively limited pool of experts in this domain -- it raises
challenges when it comes to interpreting the findings. Mainly, the field
itself is internally quite heterogeneous. Within many of the AGI labs
and other organizations, there are known to be both strongly
safety-oriented subgroups and others that are more commercially
technically, or capability-driven in focus. \
\
Without a mechanism to balance across this internal variation, there's a
risk that the sample reflects the views of those already more inclined
to endorse stringent safety norms. This is particularly important in
light of the sample composition, as over 40% of respondents are
affiliated with AGI labs. While their views are obviously relevant, this
concentration raises the possibility that the results are more
reflective of an in-group consensus than a broader cross-section of AI
researchers or practitioners. The authors note this, but given how
central the claim of expert consensus is to the paper, I think this is
an important limitation.

### \[Meaningfullness of consensus; framing of statements\]

A second issue is that the extremely high levels of agreement across the
proposed practices - many exceeding 90% - leave open questions about the
depth and meaningfulness of that consensus. As the authors note, this
may be partly due to the high-level and generally uncontroversial
framing of the statements (e.g., "AGI labs should conduct pre-deployment
risk assessments"). But in their current form, the items mostly capture
agreement in principle, rather than forcing respondents to grapple with
the kinds of tradeoffs that real-world governance inevitably entails. It
would have been interesting to see deeper testing on this - for example,
asking questions that explore whether experts are actually willing to
prioritize safety over other institutional or strategic goals. \
\
For example, would respondents still support red teaming or third-party
audits if they significantly delayed product releases? Would they
endorse specific safety measures even if they meant ceding competitive
ground to other labs or state actors? In the absence of these kinds of
questions, it\'s hard to know whether the strong consensus reflects
genuine alignment on what should happen when safety comes at a cost, or
simply shared values at a high level of abstraction. This is especially
important as AI labs have at times been criticised for pretending to
care about safety while racing towards AGI. One way to address this in
future work might be to include structured tradeoff scenarios or
split-sample experiments that force respondents to weigh safety
practices against other considerations like speed, cost, or competitive
advantage. That kind of design could help distinguish between agreement
that's merely nominal and agreement that's actually actionable.

## **Minor Comments**

-   While striving to protect respondent privacy and anonymity is
    understandable, I do not fully understand the decision to not
    publish any of the text responses collected. This is not fully
    understandable, especially as some experts are named, and
    considering that responses could have been anonymized and rephrased
    to provide information without compromising privacy.\

-   Though the authors report no statistically significant gender
    differences, visualizations (Appendix D, Figure 8) suggest women may
    demonstrate systematically higher agreement on several items (e.g.
    items related to caution, risk disclosure, and third-party
    notification). Additionally, given the limited gender balances and
    representativeness in the sample, the methodology may lack
    sufficient power to fully detect these effects.

# Evaluator details

1.  How long have you been in your field of expertise?

    -   3 years.

2.  How many proposals, papers, and projects have you evaluated/reviewed
    (for journals, grants, or other peer-review)?

    -   10\.

[^1]: Note: if you are reading this before, or soon after this has been
    publicly released, the ratings from this paper may not yet have been
    incorporated into that data presentation.

[^2]: We asked them to rank this paper "heuristically" as a percentile
    "relative to all serious research in the same area that you have
    encountered in the last three years." We requested they "consider
    all aspects of quality, credibility, importance to knowledge
    production, and importance to practice.

[^3]: See ranking tiers discussed
    [here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers).

[^4]: The evaluator was given the following instructions: Identify the
    most important and impactful factual claim this research makes --
    e.g., a binary claim or a point estimate or prediction.

    Please state the authors' claim precisely and quantitatively.
    Identify the source of the claim (i.e., cite the paper), and briefly
    mention the evidence underlying this. We encourage you to explain
    why you believe this claim is important, either here, or in the text
    of your report.

[^5]: Manager: We added these subheadings in brackets.
