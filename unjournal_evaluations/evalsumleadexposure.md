---
article:
  doi: 10.21428/d28e8e57.41f2f7c9
  elocation-id: evalsumleadexposure
author:
- Evaluator 1
- Evaluator 2
- Charlotte Lane
bibliography: /tmp/tmp-602p21kEOZWTMi.json
copyright:
  link: "https://creativecommons.org/licenses/by/4.0/"
  text: Creative Commons Attribution 4.0 International License
  type: CC-BY
csl: /app/dist/server/server/utils/citations/citeStyles/apa-6th-edition.csl
date:
  day: 05
  month: 07
  year: 2024
journal:
  publisher-name: The Unjournal
  title: The Unjournal
link-citations: true
title: "Evaluation Summary and Metrics: \"How Much Would Reducing Lead
  Exposure Improve Children's Learning in the Developing World?\""
uri: "https://unjournal.pubpub.org/pub/evalsumleadexposure"
---

# Abstract 

We organized two evaluations of the paper: \"How Much Would Reducing
Lead Exposure Improve Children's Learning in the Developing World?\".
The evaluators were moderately positive, but offered critique of the
*non-systematic* nature of this review and its departure from "best
practices". To read these evaluations, please see the links below.

## **Evaluations**

1\. [Anonymous evaluator
1](https://unjournal.pubpub.org/pub/eval1leadexposure "null")

2\. [Anonymous evaluator
2](https://unjournal.pubpub.org/pub/eval2leadexposure "null")

# **Overall ratings**

We asked evaluators to provide overall assessments as well as ratings
for a range of specific criteria. * *

**I. Overall assessment: **We asked them to rank this paper
"heuristically" as a percentile "relative to all serious research in the
same area that you have encountered in the last three years." We
requested they "consider all aspects of quality, credibility, importance
to knowledge production, and importance to practice."

**II. Journal rank tier, normative rating (0-5): **On a 'scale of
journals', what 'quality of journal' should this be published in? (See
ranking tiers discussed
[here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers "null").)
*Note: 0= lowest/none, 5= highest/best.*

+---+-------------------+---+
|   | **Overall         | * |
|   | assessment        | * |
|   | (0-100)**         | J |
|   |                   | o |
|   |                   | u |
|   |                   | r |
|   |                   | n |
|   |                   | a |
|   |                   | l |
|   |                   | r |
|   |                   | a |
|   |                   | n |
|   |                   | k |
|   |                   | t |
|   |                   | i |
|   |                   | e |
|   |                   | r |
|   |                   | , |
|   |                   | n |
|   |                   | o |
|   |                   | r |
|   |                   | m |
|   |                   | a |
|   |                   | t |
|   |                   | i |
|   |                   | v |
|   |                   | e |
|   |                   | r |
|   |                   | a |
|   |                   | t |
|   |                   | i |
|   |                   | n |
|   |                   | g |
|   |                   | ( |
|   |                   | 0 |
|   |                   | - |
|   |                   | 5 |
|   |                   | ) |
|   |                   | * |
|   |                   | * |
+===+===================+===+
| A | 70                | 2 |
| n |                   | . |
| o |                   | 5 |
| n |                   |   |
| y |                   |   |
| m |                   |   |
| o |                   |   |
| u |                   |   |
| s |                   |   |
| e |                   |   |
| v |                   |   |
| a |                   |   |
| l |                   |   |
| u |                   |   |
| a |                   |   |
| t |                   |   |
| i |                   |   |
| o |                   |   |
| n |                   |   |
| 1 |                   |   |
+---+-------------------+---+
| A | 75                | 3 |
| n |                   | . |
| o |                   | 0 |
| n |                   |   |
| y |                   |   |
| m |                   |   |
| o |                   |   |
| u |                   |   |
| s |                   |   |
| e |                   |   |
| v |                   |   |
| a |                   |   |
| l |                   |   |
| u |                   |   |
| a |                   |   |
| t |                   |   |
| i |                   |   |
| o |                   |   |
| n |                   |   |
| 2 |                   |   |
+---+-------------------+---+

*See
"*[*Metrics*](https://unjournal.pubpub.org/pub/evalsumleadexposure#metrics "null")*"
below for a more detailed breakdown of the evaluators' ratings across
several categories. To see these in the context of all Unjournal
ratings, with some analysis, see our *[*data presentation
here.*](https://unjournal.github.io/unjournaldata/chapters/evaluation_data_analysis.html#basic-presentation "null")[^1]*
*

*See
*[*here*](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#metrics-overall-assessment-categories "null")*
for the current full evaluator guidelines, including further explanation
of the requested ratings.*[^2]

# Evaluation summaries

## Anonymous evaluator 1

Strengths include excellent explanations of how the literature was
harmonized for comparison and how various analytical methods were
considered. Authors make compelling cases for both. The major
limitations are around the actual systematic review methodology that is
employed as well as the causal conclusions drawn. Authors have not used
published best-practices in the conduct of a systematic review, and have
not noted this as a limitation of the work. It will be critical to add
methodological limitations. There is also a lot of causal language used
that cannot be supported by the type of data presented (correlational),
thus the suggestion is to focus on the associations or relationships
between the IVs and DVs, rather than speaking about \'effects\'.

## Anonymous evaluator 2

This non-systematic review[^3] seeks to explore the relationship between
lead exposure and children's learning outcomes by updating existing
meta-analyses. Its key strengths are 1) consideration of standardized
test scores for reading and mathematics 2) use of a specification curve,
and different ways to assess the impacts of publication bias.
Critically, a quality assessment is missing and some control choices are
unmotivated. This evidence captured in the review itself is likely not
causal, though the authors do examine a broader literature on the
cognitive implications of lead exposure that certainly goes beyond
correlational associations. 

# Metrics

## Ratings

[See
here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators "null")
for details on the categories below, and the guidance given to
evaluators.

+-----------------------------------+-----------+--------+-----------+-----------+--------------+-----------+
|                                   | **        |        |           | **        |              |           |
|                                   | Evaluator |        |           | Evaluator |              |           |
|                                   | 1**       |        |           | 2**       |              |           |
|                                   | Anonymous |        |           | Anonymous |              |           |
+===================================+===========+========+===========+===========+==============+===========+
| **Rating category**               | **Rating  | **90%  | **C       | **Rating  | **90% CI     | **C       |
|                                   | (0-100)** | CI     | omments** | (0-100)** | (0-100)**    | omments** |
|                                   |           | (0-    |           |           |              |           |
|                                   |           | 100)** |           |           |              |           |
+-----------------------------------+-----------+--------+-----------+-----------+--------------+-----------+
| Overall assessment[^4]            | 70        | (55,   | [^5]      | 75        | (68, 82)     |           |
|                                   |           | 74)    |           |           |              |           |
+-----------------------------------+-----------+--------+-----------+-----------+--------------+-----------+
| **A**dvancing knowledge and       | 80        | (65,   | [^7]      | 70        | (65, 75)     | [^8]      |
| practice[^6]                      |           | 85)    |           |           |              |           |
+-----------------------------------+-----------+--------+-----------+-----------+--------------+-----------+
| Methods: Justification,           | 60        | (44,   | [^10]     | 68        | (58, 78)     | [^11]     |
| reasonableness, validity,         |           | 82)    |           |           |              |           |
| robustness[^9]                    |           |        |           |           |              |           |
+-----------------------------------+-----------+--------+-----------+-----------+--------------+-----------+
| Logic & communication[^12]        | 66        | (58,   | [^13]     | 75        | (70, 80)     |           |
|                                   |           | 75)    |           |           |              |           |
+-----------------------------------+-----------+--------+-----------+-----------+--------------+-----------+
| Open, collaborative,              | 61        | (52,   | [^15]     | 80        | (70, 90)     | [^16]     |
| replicable[^14]                   |           | 73)    |           |           |              |           |
+-----------------------------------+-----------+--------+-----------+-----------+--------------+-----------+
| Real-world relevance[^17]         | 80        | (73,   | [^18]     | 70        | (65, 75)     | [^19]     |
|                                   |           | 85)    |           |           |              |           |
+-----------------------------------+-----------+--------+-----------+-----------+--------------+-----------+
| Relevance to global               | 83        | (77,   | [^21]     | 80        | (70, 90)     |           |
| priorities[^20]                   |           | 87)    |           |           |              |           |
+-----------------------------------+-----------+--------+-----------+-----------+--------------+-----------+

## Journal ranking tiers

[See
here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers "null")
for more details on these tiers.

+-------------------------------+-------------+---------+-----------+-----------+--------+------------+
|                               | **Evaluator |         |           | **        |        |            |
|                               | 1**         |         |           | Evaluator |        |            |
|                               |             |         |           | 2**       |        |            |
|                               | Anonymous   |         |           |           |        |            |
|                               |             |         |           | Anonymous |        |            |
+===============================+=============+=========+===========+===========+========+============+
| **Judgment**                  | **Ranking   | **90%   | *         | **Ranking | **90%  | **         |
|                               | tier        | CI **   | *Comments | tier      | CI **  | Comments** |
|                               | (0-5)**     |         | **        | (0-5)**   |        |            |
+-------------------------------+-------------+---------+-----------+-----------+--------+------------+
| On a 'scale of journals',     | 2.5         | (2.0,   | [^22]     | 3.0       | (2.8,  |            |
| what 'quality of journal'     |             | 3.0)    |           |           | 3.2)   |            |
| *should* this be published    |             |         |           |           |        |            |
| in?                           |             |         |           |           |        |            |
+-------------------------------+-------------+---------+-----------+-----------+--------+------------+
| What 'quality journal' do you | 3.0         | (2.0,   |           | 3.2       | (2.8,  |            |
| expect this work *will* be    |             | 3.5)    |           |           | 4.2)   |            |
| published in?                 |             |         |           |           |        |            |
+-------------------------------+-------------+---------+-----------+-----------+--------+------------+
| [See                          | *We         |         |           |           |        |            |
| here](https://                | summarize   |         |           |           |        |            |
| globalimpact.gitbook.io/the-u | these as:*  |         |           |           |        |            |
| njournal-project-and-communic |             |         |           |           |        |            |
| ation-space/policies-projects | -   0.0:    |         |           |           |        |            |
| -evaluation-workflow/evaluati |             |         |           |           |        |            |
| on/guidelines-for-evaluators# |  Marginally |         |           |           |        |            |
| journal-ranking-tiers "null") |     respect |         |           |           |        |            |
| for more details on these     | able/Little |         |           |           |        |            |
| tiers.                        |     to no   |         |           |           |        |            |
|                               |     value   |         |           |           |        |            |
|                               |             |         |           |           |        |            |
|                               | -   1.0:    |         |           |           |        |            |
|                               |             |         |           |           |        |            |
|                               | OK/Somewhat |         |           |           |        |            |
|                               |             |         |           |           |        |            |
|                               |    valuable |         |           |           |        |            |
|                               |             |         |           |           |        |            |
|                               | -   2.0:    |         |           |           |        |            |
|                               |             |         |           |           |        |            |
|                               |    Marginal |         |           |           |        |            |
|                               |     B-jou   |         |           |           |        |            |
|                               | rnal/Decent |         |           |           |        |            |
|                               |     field   |         |           |           |        |            |
|                               |     journal |         |           |           |        |            |
|                               |             |         |           |           |        |            |
|                               | -   3.0:    |         |           |           |        |            |
|                               |     Top     |         |           |           |        |            |
|                               |     B-jou   |         |           |           |        |            |
|                               | rnal/Strong |         |           |           |        |            |
|                               |     field   |         |           |           |        |            |
|                               |     journal |         |           |           |        |            |
|                               |             |         |           |           |        |            |
|                               | -   4.0:    |         |           |           |        |            |
|                               |             |         |           |           |        |            |
|                               |    Marginal |         |           |           |        |            |
|                               |     A-      |         |           |           |        |            |
|                               | Journal/Top |         |           |           |        |            |
|                               |     field   |         |           |           |        |            |
|                               |     journal |         |           |           |        |            |
|                               |             |         |           |           |        |            |
|                               | -   5.0:    |         |           |           |        |            |
|                               |     A-      |         |           |           |        |            |
|                               | journal/Top |         |           |           |        |            |
|                               |     journal |         |           |           |        |            |
+-------------------------------+-------------+---------+-----------+-----------+--------+------------+

#  {#r5386701504}

# Evaluation manager's discussion

This synthesis project establishes the relationship between lead
exposure and learning outcomes across a range of studies and contexts.
Both evaluators found limitations in the approach used to identify the
literature included in this analysis, the choice of outcome variables,
and the use of specification curves. As such, we do not have high
confidence in the point estimates calculated by the authors.
Nonetheless, the policy simulations offered by the authors are novel,
insightful, and interesting. Given that these are simulations and not
statements of objective fact, they can be informative despite low
confidence in the meta-analysis. However, they should not be interpreted
as garneted likely effects, rather, they represent plausible outcomes
given current information constraints. Future primary research should
attempt to evaluate the effects of the considered policies on "real
world" outcomes (such as education) as opposed to only measuring
biochemical outcomes (such as BLL).

While the evaluators were moderately positive, they both offered
critiques of the *non-systematic* nature of this review and its
departure from "best practices". We agree with the second evaluator that
results from Google Scholar are inherently non-systematic
because results almost always vary between machines given the algorithms
Google Scholar uses, making it non-replicable. We were unable to
replicate the search results reported ourselves, finding many more
results than the authors reported. 

As we requested, the evaluators focused on areas of their *own*
expertise. However, there are several aspects of the paper we would like
to see evaluated more carefully in future. These include:

-   the plausibility of the highlighted results (see ['claim
    identification'](https://docs.google.com/document/d/1mBkAmCVomcUt0Ks7hsxShTsjAbx3WVtFfMCnasGQxns/edit?usp=sharing "null"))
    in the context of other work; overall quantification

-   The particular adjustment methods used (e.g., for reporting bias');
    other adjustments that might be warranted (e.g., for "type M error")

-   The use of random effects REML models

-   Particular issues of causal inference/observational studies

    -   considering confoundedness and adjusting/weighting for this; the
        'coefficient stability method'

    -    IV and OLS estimates compared

-   The policy simulation details and implications

# Unjournal process notes   

## Why we chose this paper

This paper was selected due to the significant policy and equity
implications. Authors make a compelling argument for large-scale action
across countries. If the effects suggested by the authors are correct,
the proposed lead reduction programs could meaningfully contribute to
improved human capital production in LMICs, and a reduction in global
disparities. We want to ensure that decision-makers understand how
credible this evidence is as they use it to develop national policies.

## How we chose the evaluators

Evaluators were selected based on their knowledge and expertise in the
field. Evaluators had expertise in child development, education, and
evidence synthesis. Evaluators were invited to submit reviews and
compensated for their time.

## Conflict of interests

Evaluators, the evaluation manager, and others involved in this review
at the Unjournal have no conflicts to report.

# References

[@n0cjnmliyuk] Crawfurd, Lee, Rory Todd, Susannah Hares, Justin
Sandefur, and Rachel Bonnifield. 2023. *How Much Would Reducing Lead
Exposure Improve Children's Learning in the Developing World?*. Center
for Global Development.

[^1]: Note: if you are reading this before, or soon after this has been
    publicly released, the ratings from this paper may not yet have been
    incorporated into that data presentation.

[^2]: See "1 Mar 2024 note" above. See
    [here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators/why-these-guidelines#adjustments-to-metrics-and-guidelines-previous-presentations)
    to learn how this changed, and to see the earlier instructions.

[^3]: Managers' note: we asked the evaluator to clarify this
    categorization as 'non-systematic'. They responded with a discussion
    of the use of Google Scholar, which we excerpt in the 'additional
    note' at the bottom of the evaluation.

[^4]: Judge the quality of the research heuristically. Consider all
    aspects of quality, credibility, importance to knowledge production,
    and importance to practice.

[^5]: This is a topical area of critical importance, but some of the
    methodology used in the production of the review is likely to
    introduce some level of bias into the results.

    \

[^6]: To what extent does the project contribute to the field or to
    practice, particularly in ways that are directly or indirectly
    relevant to global priorities and impactful interventions?

[^7]: I think that once the methodological limitations are acknowledged
    and the causal language is tamped down, this work can be
    appropriately caveated and contribute to our understanding of the
    relationships between blood lead levels and cognitive outcomes.

[^8]: Consideration of reading and maths is useful and goes beyond
    standard of IQ measures, which have previously been critiqued for
    both young children and in some non-western cultural contexts

[^9]: Are methods clearly justified and explained? Are methods and their
    underlying assumptions reasonable? Are the results likely to be
    robust to changes in the assumptions? Have the authors avoided bias
    and questionable research practices?

[^10]: Methods related to the actual conduct of the review are
    underexplained and do not appear to follow best practices. However,
    their justifications for their specific analytical choices as well
    as their explanation of how data were harmonized to allow for them
    to be combined in a meta-analysis were very well thought out and
    well described.

[^11]: Wide CIs - I view very positively the reporting of a
    specification curve, the different approaches to assessing
    publication bias, the consideration of different interventional
    approaches. At the same time, the lack of quality appraisal and the
    lack of motivation for controls are concerning.

[^12]: Are concepts clearly defined? Is the reasoning transparent? Are
    conclusions consistent with the evidence (or formal proofs)
    presented? Are the data and/or analysis, including tables and
    figures, relevant to the argument?

[^13]: Here some work needs to be done

[^14]: Would another researcher be able to replicate the analysis? Are
    the method and its details explained sufficiently? Is the source of
    the data clear? Is the data made as widely available as possible,
    with clear labeling and explanation? Do the authors provide
    resources that are likely to enable future research and
    meta-analysis?

[^15]: Sufficient information is given for someone to attempt to
    replicate the search, but I did not see any links to open access
    data.

[^16]: Data and code are not shared, so effort would have to be expanded
    to replicate this, but enough data are reported in text for this to
    happen

[^17]: Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic and relevant to practitioners?

[^18]: This is outside of my topic area as I am primarily a review
    methodologist, however the policy relevance as well as the
    real-world relevance for children and families around the world is
    clear.

[^19]: Limited novelty is what detracts from my score, as the negative
    effects of lead on cognition are well established and without a
    better sense of the quality of data meta-analyzed, it is difficult
    for me to support any other significant contributions

[^20]: Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?

[^21]: Yes, this is a major global concern and should be of wide
    interest.

[^22]: It would be of interest to a field journal, but would be unlikely
    to be published in a top journal due to the methodological
    limitation of the review process.
