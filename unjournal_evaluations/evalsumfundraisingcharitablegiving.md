---
affiliation:
- id: 0
  organization: UC Berkeley
- id: 1
  organization: Swedish University of Agricultural Sciences
article:
  elocation-id: evalsumfundraisingcharitablegiving
author:
- David Reiley
- Tabaré Capitán
- Anirudh Tagat
bibliography: /tmp/tmp-4463T1k5tOk6r6.json
copyright:
  link: "https://creativecommons.org/licenses/by/4.0/"
  text: Creative Commons Attribution 4.0 International License
  type: CC-BY
csl: /app/dist/server/server/utils/citations/citeStyles/apa-6th-edition.csl
date:
  day: 10
  month: 10
  year: 2025
journal:
  publisher-name: The Unjournal
  title: The Unjournal
link-citations: true
title: "Evaluation Summary and Metrics: \"Does online fundraising
  increase charitable giving? A nationwide field experiment on
  Facebook\""
uri: "https://unjournal.pubpub.org/pub/evalsumfundraisingcharitablegiving"
---

# Abstract 

We organized two evaluations of the paper: "Does online fundraising
increase charitable giving? A nationwide field experiment on Facebook"
[@n4sgp51xwph]. To read these evaluations, please see the links below.

## **Evaluations**

1\. E1: [Tabaré
Capitán](https://unjournal.pubpub.org/pub/e1fundraisingcharitablegivingcapitan/draft?access=c3r1bzw0 "null")

2.  E2: [David
    Reiley](https://unjournal.pubpub.org/pub/e2fundraisingcharitablegivingreiley/draft?access=y9rs7g73 "null")

# **Overall ratings**

We asked evaluators to provide overall assessments as well as ratings
for a range of specific criteria. * *

**I. Overall assessment **(See footnote[^1])

**II. Journal rank tier, normative rating (0-5): **On a 'scale of
journals', what 'quality of journal' should this be published in?[^2]
*Note: 0= lowest/none, 5= highest/best. *

+---+-------------------+---+
|   | **Overall         | * |
|   | assessment        | * |
|   | (0-100)**         | J |
|   |                   | o |
|   |                   | u |
|   |                   | r |
|   |                   | n |
|   |                   | a |
|   |                   | l |
|   |                   | r |
|   |                   | a |
|   |                   | n |
|   |                   | k |
|   |                   | t |
|   |                   | i |
|   |                   | e |
|   |                   | r |
|   |                   | , |
|   |                   | n |
|   |                   | o |
|   |                   | r |
|   |                   | m |
|   |                   | a |
|   |                   | t |
|   |                   | i |
|   |                   | v |
|   |                   | e |
|   |                   | r |
|   |                   | a |
|   |                   | t |
|   |                   | i |
|   |                   | n |
|   |                   | g |
|   |                   | ( |
|   |                   | 0 |
|   |                   | - |
|   |                   | 5 |
|   |                   | ) |
|   |                   | * |
|   |                   | * |
+===+===================+===+
| T | 92                | 4 |
| a |                   | . |
| b |                   | 8 |
| a |                   |   |
| r |                   |   |
| é |                   |   |
| C |                   |   |
| a |                   |   |
| p |                   |   |
| i |                   |   |
| t |                   |   |
| á |                   |   |
| n |                   |   |
+---+-------------------+---+
| D | 90                | 4 |
| a |                   | . |
| v |                   | 5 |
| i |                   |   |
| d |                   |   |
| R |                   |   |
| e |                   |   |
| i |                   |   |
| l |                   |   |
| e |                   |   |
| y |                   |   |
+---+-------------------+---+

*See
"*[*Metrics*](https://unjournal.pubpub.org/pub/evalsumfundraisingcharitablegiving#metrics "null")*"
below for a more detailed breakdown of the evaluators' ratings across
several categories. To see these ratings in the context of all Unjournal
ratings, with some analysis, see our *[*data presentation
here.*](https://unjournal.github.io/unjournaldata/chapters/evaluation_data_analysis.html#basic-presentation "null")[^3]*
*

*See
*[*here*](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#metrics-overall-assessment-categories "null")*
for the current full evaluator guidelines, including further explanation
of the requested ratings.*

# Evaluation summaries

## Tabaré Capitán {#tabar-capitn}

This is a large-scale, well-executed field experiment on Facebook ads
for charitable giving in Germany. Randomized at the postal code level,
the study finds that the campaign increased donations both short- and
medium-term, without reducing future giving to the same charity---but
possibly crowding out donations to others. Content and delivery method
had no differential effect. The design is strong and materials are fully
replicable.

## David Reiley

The experiment is a well-designed example of geographic randomization to
measure the treatment effects of an advertising campaign.\
\
The authors demonstrate a marginally significant ATE.  They also
demonstrate large, positive, significant spillover effects across
geographically close postal codes, indicating that their ATE is a lower
bound on the truth.  I would like to see more exploration of this
result, because it is a surprisingly large effect.\
\
I love that the authors measure the final outcome of actual donations
made, instead of some intermediate proxy, because I am never confident
that a proxy actually tells us what researchers want it to tell us about
final outcomes.   But I think the authors might be more careful to
present confidence intervals and point out how much statistical
uncertainty they have in their estimates.

# Metrics

## Ratings

[See
here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#quantitative-metrics "null")
for details on the categories below, and the guidance given to
evaluators.

+-----------------------+---------------+---------+-----------+--------------+----------+-----------+
|                       | **Evaluator   |         |           | **Evaluator  |          |           |
|                       | 1**           |         |           | 2**          |          |           |
|                       |               |         |           |              |          |           |
|                       | Tabaré        |         |           | David Reiley |          |           |
|                       | Capitán       |         |           |              |          |           |
+=======================+===============+=========+===========+==============+==========+===========+
| **Rating category**   | **Rating      | **90%   | **C       | **Rating     | **90% CI | **C       |
|                       | (0-100)**     | CI **   | omments** | (0-100)**    | **       | omments** |
|                       |               |         |           |              |          |           |
|                       |               | **(0    |           |              | **(      |           |
|                       |               | -100)\* |           |              | 0-100)\* |           |
|                       |               | **      |           |              | **       |           |
+-----------------------+---------------+---------+-----------+--------------+----------+-----------+
| Overall               | 92            | (85,    |           | 90           | (85, 95) | [^5]      |
| assessment[^4]        |               | 95)     |           |              |          |           |
+-----------------------+---------------+---------+-----------+--------------+----------+-----------+
| Claims, strength,     | 85            | (80,    |           | 85           | (80, 90) | [^7]      |
| characterization of   |               | 90)     |           |              |          |           |
| evidence[^6]          |               |         |           |              |          |           |
+-----------------------+---------------+---------+-----------+--------------+----------+-----------+
| Advancing knowledge   | 90            | (80,    | [^9]      | 90           | (80, 95) | [^10]     |
| and practice[^8]      |               | 95)     |           |              |          |           |
+-----------------------+---------------+---------+-----------+--------------+----------+-----------+
| Methods:              | 97            | (95,    |           | 90           | (85, 94) | [^12]     |
| Justification,        |               | 99)     |           |              |          |           |
| reasonableness,       |               |         |           |              |          |           |
| validity,             |               |         |           |              |          |           |
| robustness[^11]       |               |         |           |              |          |           |
+-----------------------+---------------+---------+-----------+--------------+----------+-----------+
| Logic &               | 92            | (90,    |           | 93           | (90, 98) | [^14]     |
| communication[^13]    |               | 95)     |           |              |          |           |
+-----------------------+---------------+---------+-----------+--------------+----------+-----------+
| Open, collaborative,  | 97            | (93,    |           | 92           | (88, 95) | [^16]     |
| replicable[^15]       |               | 100)    |           |              |          |           |
+-----------------------+---------------+---------+-----------+--------------+----------+-----------+
| Real-world relevance  | N/A           | N/A     |           | 90           | (80, 94) | [^19]     |
| [^17],[^18]           |               |         |           |              |          |           |
+-----------------------+---------------+---------+-----------+--------------+----------+-----------+
| Relevance to global   | N/A           | N/A     |           | 90           | (80, 94) |           |
| priorities[^20],      |               |         |           |              |          |           |
| [^21]                 |               |         |           |              |          |           |
+-----------------------+---------------+---------+-----------+--------------+----------+-----------+

## Journal ranking tiers

[See
here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers "null")
for more details on these tiers.

+-------------------------------+---------------+-------------+-------------+----------+----------+
|                               | **Evaluator   |             | **Evaluator |          |          |
|                               | 1**           |             | 2**         |          |          |
|                               |               |             |             |          |          |
|                               | Tabaré        |             | David       |          |          |
|                               | Capitán       |             | Reiley      |          |          |
+===============================+===============+=============+=============+==========+==========+
| **Judgment**                  | **Ranking     | **90% CI ** | **Ranking   | **90% CI | **       |
|                               | tier (0-5)**  |             | tier        | **       | Comments |
|                               |               |             | (0-5)**     |          | **       |
+-------------------------------+---------------+-------------+-------------+----------+----------+
| On a 'scale of journals',     | 4.8           | (4.6, 5.0)  | 4.5         | (3.9,    | [^22]    |
| what 'quality of journal'     |               |             |             | 4.7)     |          |
| *should* this be published    |               |             |             |          |          |
| in?                           |               |             |             |          |          |
+-------------------------------+---------------+-------------+-------------+----------+----------+
| [See                          | *We summarize |             |             |          |          |
| here](https://                | these as:*    |             |             |          |          |
| globalimpact.gitbook.io/the-u |               |             |             |          |          |
| njournal-project-and-communic | -   0.0:      |             |             |          |          |
| ation-space/policies-projects |               |             |             |          |          |
| -evaluation-workflow/evaluati |    Marginally |             |             |          |          |
| on/guidelines-for-evaluators# |     respe     |             |             |          |          |
| journal-ranking-tiers "null") | ctable/Little |             |             |          |          |
| for more details on these     |     to no     |             |             |          |          |
| tiers.                        |     value     |             |             |          |          |
|                               |               |             |             |          |          |
|                               | -   1.0:      |             |             |          |          |
|                               |               |             |             |          |          |
|                               |   OK/Somewhat |             |             |          |          |
|                               |     valuable  |             |             |          |          |
|                               |               |             |             |          |          |
|                               | -   2.0:      |             |             |          |          |
|                               |     Marginal  |             |             |          |          |
|                               |     B-j       |             |             |          |          |
|                               | ournal/Decent |             |             |          |          |
|                               |     field     |             |             |          |          |
|                               |     journal   |             |             |          |          |
|                               |               |             |             |          |          |
|                               | -   3.0: Top  |             |             |          |          |
|                               |     B-j       |             |             |          |          |
|                               | ournal/Strong |             |             |          |          |
|                               |     field     |             |             |          |          |
|                               |     journal   |             |             |          |          |
|                               |               |             |             |          |          |
|                               | -   4.0:      |             |             |          |          |
|                               |     Marginal  |             |             |          |          |
|                               |               |             |             |          |          |
|                               | A-Journal/Top |             |             |          |          |
|                               |     field     |             |             |          |          |
|                               |     journal   |             |             |          |          |
|                               |               |             |             |          |          |
|                               | -   5.0:      |             |             |          |          |
|                               |               |             |             |          |          |
|                               | A-journal/Top |             |             |          |          |
|                               |     journal   |             |             |          |          |
+-------------------------------+---------------+-------------+-------------+----------+----------+

# Claim identification and assessment (summary)

For *the full discussions, see the* *corresponding sections in each
linked evaluation.*

+-------------------+------------------------------------------------------------------+----------------------------------+-------------------------------------------------------------+------------------------------------------------+
|                   | **Main research claim**[^23]                                     | **Belief in claim**[^24]         | **Suggested robustness checks**[^25]                        | ** Important 'implication', policy,            |
|                   |                                                                  |                                  |                                                             | credibility**[^26]                             |
+===================+==================================================================+==================================+=============================================================+================================================+
| **Evaluator 1 **\ | Abstract: However, we also found some crowding out of donations  | Like 90%. They don't have the    |                                                             |                                                |
| Tabaré Capitán    | to other similar charities or projects. Table 3 shows a negative | same level of data quality as    |                                                             |                                                |
|                   | change in revenue in 23 other similar charities in response to   | their main dataset, but it is    |                                                             |                                                |
|                   | the exogenous variation created by the campaign. It is           | very comprehensive.              |                                                             |                                                |
|                   | particularly important because, according to the authors, there  |                                  |                                                             |                                                |
|                   | is a belief in this literature that charities are complements.   |                                  |                                                             |                                                |
|                   | In other words, a new donor is good news for everyone. In        |                                  |                                                             |                                                |
|                   | contrast, this result imply competition. If this is the case,    |                                  |                                                             |                                                |
|                   | then any funds spent on fundraising may be simply                |                                  |                                                             |                                                |
|                   | re-distributing a fixed cake (and making it smaller).            |                                  |                                                             |                                                |
+-------------------+------------------------------------------------------------------+----------------------------------+-------------------------------------------------------------+------------------------------------------------+
| **Evaluator 2**\  | The most stunning result in the paper is the measurement of huge | I think the claim is probably    | I would like to know whether the huge result is robust to   | If true, the spillover claim means that the    |
| David Reiley      | geographic spillovers in a geo-randomized advertising experiment | true, but I worry that it may be | different variations on the arbitrary assumptions chosen by | Facebook ad campaign might be much more        |
|                   | on Facebook in Germany. The secondary question about spillovers  | exaggerated by the choice of     | the authors.  Differences in the distance threshold.        | effective than what was measured in the main   |
|                   | shows an indirect effect (the effect of treating neighboring     | functional form.   I cannot find |  Allowing the spillover effect to vary continuously with    | average treatment effect.   If this is a       |
|                   | postal codes) that is ten times higher than the direct effect    | any concrete reason I expect the | distance, rather than being a step function that is "on" if | generally true phenomenon in digital           |
|                   | (the effect of treating one's own postal code).                  | claim to be false, but the       | the neighboring postal code is within 30km and "off"        | advertising, it means that folks are generally |
|                   |                                                                  | spillover effects seem           | otherwise.  Modeling the spillover effect not just as       | underestimating the effects of advertising     |
|                   |                                                                  | implausibly huge to me.          | proportional to the share of treated neighboring postal     | with geo-experiments, so ad campaigns might be |
|                   |                                                                  |                                  | codes, but as proportional to the share of population that  | a lot more effective (3x, 5x, 10x) than has    |
|                   |                                                                  |                                  | was treated in the neighboring postal codes.                | been typically measured in advertising         |
|                   |                                                                  |                                  |                                                             | experiments.                                   |
+-------------------+------------------------------------------------------------------+----------------------------------+-------------------------------------------------------------+------------------------------------------------+

# Evaluation manager's discussion 

The evaluations for "Does online fundraising increase charitable
giving?" demonstrate a close reading of the key claims in the paper as
well as the methods (and assumptions) required to substantiate the
findings related to those claims. While we did not give any explicit
direction to evaluators on what to examine in this paper, the choice of
evaluators was driven mainly by the concern of getting to both
methodological as well as conceptual issues related to the paper. This
bears out in the two evaluations we received. 

Tabare Capitan's (E1) evaluation generally aligns with feedback typical
for a late-stage paper in applied economics (i.e., one that is "nearly
there", potentially accepted for publication at a "top" journal, as in
the case of this paper). However, the evaluation highlights a larger
question around reporting standards in such large-scale experiments that
are done typically in partnership with non-profits or charitable
organizations. One relates to reports around profitability of such
demonstrably effective campaigns. How should we deal with statistical
imprecision in such estimates? (This issue was also raised by E2, David
Reiley). A related issue flagged here is that advertising on online
platforms is highly dynamic, and tech platforms may shift goalposts
considerably, potentially rendering any estimate around costs of such ad
campaigns as parameters that might need to be revisited according to the
context and timing of the study. Finally, the evaluation raises two more
questions in an illuminating fashion, that almost all randomized
experiments (and experimenters) need to grapple with: (a) external
validity (i.e., are the results informative about charitable giving in
Germany, outside Germany, in child-centric sectors of giving?) and (b)
reporting results "of" randomization, which rather than simply reporting
on balance between observable covariates, perhaps also need to be
constructed to report standardized differences in covariates. \[Tagat
mentioned similar concerns in his pre-evaluation notes, see
footnote.[^27]\]

David Reiley's (E2) evaluation is one of the most comprehensive
evaluations I have come across, reflecting a deep engagement with work
in this domain, both from the perspective of a researcher studying
charitable giving, but also from someone with the practical experience
of having worked in the sector. I will not go into depth into each
aspect of his evaluation, as any researcher interested in working in
this domain should read this (as well as E1) very carefully to get
pointers on how best to design and test such campaigns. It covers
everything from investigating the (non-pre-registered) treatment of the
outcome variable (trimming, winsorizing etc.) to other deviations from
the pre-registration plan. While certain logistical challenges
(especially in the world outside academia, e.g., charitable
organizations) are bound to come up, E2 makes a strong case for
justifying why, where, when, and how these deviations can affect
reporting standards and outcomes in field experiments. 

Reiley's evaluation also requested clarifications on the geographical
spillovers (which I also flagged in my initial notes on the paper, see
footnote[^28]) -- these were addressed in the authors' responses.
Reiley's evaluation also carefully walks the reader through various
issues in randomization inference, heterogenous treatment effects, and
other measurement issues with the care of a university professor but the
passion of an ardent practitioner working to get this right. This is
both rare and incredibly useful in the field of economics, and I am
grateful that Reiley's evaluation covers this in great detail.

My own takeaway from these evaluations is that they provide rigorous
insight into the kind of work that economists set out to do in
partnership with a wide array of organizations (even if this particular
paper is only related to charitable giving, it does speak at length
about what kind of advertising is effective in raising giving). There
are various practical, methodological, and technical challenges that
researchers need to take into account, carefully weighing the tradeoffs
between them and greater (or lower) causal inference. 

# Unjournal process notes

## COI Issues

David Reinstein played a role in prioritizing this paper for evaluation,
and his [own research
agenda](https://scholar.google.com/citations?hl=en&user=ZGVPBmUAAAAJ "null")
includes several papers considering questions addressed in this paper,
including the competition between charities, and the effect of
quantitative impact information on donor choices. However, five other
members of our team also voted in favor of prioritizing this paper for
evaluation.

As co-director of the journal, David Reinstein tried to take a
hands-off/arms-length approach to this evaluation, although he was in
some contact with Anirudh Tagat, the evaluation manager, and in
correspondence with David Reiley during the final stages of this
evaluation process.

Tabaré Capitan (evaluator 1) is a member of our Field Specialist team.
however, he did not play a role in prioritizing this paper for
evaluation.

## Why we chose this paper

From our prioritization discussion and other threads, considering the
potential for impact on global priorities.

> The issue of the "crowding-out" of fundraising is important and still
> unresolved. The design appears strong (variation at the postal code
> level), potentially pretty close to a gold standard for studying this.
> Seems to contain some methodological contributions to field
> experimental work relevant to impactful charitable giving. Possible
> downsides: not obvious how the mere 'existence' of crowding out (which
> is probably the conventional wisdom) yields impactful actionable
> insights, and the results here might not be generalizable to other
> charity pairings/asks of more interest. Still, this arguably presents
> the strongest/most relevant evidence about this.   E.g., Save the
> Children *is* a development charity.

> My impression was that this presented some of the most credible
> evidence on the impact of Facebook ads and on crowding
> out/substitution in the context of charitable giving for global
> poverty. The 'geo-randomization' approach is particularly compelling.

## Authors' engagement

The authors were aware of this evaluation process but decided not to
respond extensively, for compelling personal reasons. Also highlighted
two fairly small points meriting correction in David Reiley's report.
Excerpting their response letter:

> The length and thoroughness of their evaluations clearly demonstrate
> the significant time and intellectual effort they invested in engaging
> deeply with our research. We are truly grateful for their insightful
> and constructive comments, which reflect a genuine commitment to
> advancing the quality and impact of research in this important field.
>
> We also express our sincere appreciation to the editors of The
> Unjournal... Their support made this valuable dialogue possible and
> highlighted new perspectives on our work.
>
> Since our paper has already been published in Management Science, we
> do not intend to provide a detailed point-by-point response at this
> stage. Nevertheless, we find the evaluators' suggestions and
> reflections very valuable and will carefully consider them as we
> continue our research agenda and develop future projects. We welcome
> this opportunity for public scientific discourse and hope that these
> evaluations encourage further inquiry and application in the realm of
> online charitable fundraising.

# References

[@nnmowcfvc5p] Adena, Maja, and Anselm Hager. 2025. 'Does Online
Fundraising Increase Charitable Giving? A Nationwide Field Experiment on
Facebook'. *Management Science* 71 (4): 3216--31.
<https://doi.org/10.1287/mnsc.2020.00596>.

[^1]: We asked them to rank this paper "heuristically" as a percentile
    "relative to all serious research in the same area that you have
    encountered in the last three years." We requested they "consider
    all aspects of quality, credibility, importance to knowledge
    production, and importance to practice.

[^2]: See ranking tiers discussed
    [here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers).

[^3]: Note: if you are reading this before, or soon after this has been
    publicly released, the ratings from this paper may not yet have been
    incorporated into that data presentation.

[^4]: Judge the quality of the research heuristically. Consider all
    aspects of quality, credibility, importance to knowledge production,
    and importance to practice.

[^5]: I really appreciate seeing a study of advertising that looks at
    final consumer outcomes.  I think the authors have done a nice job.
     My main complaint is that they oversell some of their statistically
    insignificant, and marginally significant, results.

[^6]: "Do the authors do a good job of (i) stating their main questions
    and claims, (ii) providing strong evidence and powerful approaches
    to inform these, and (iii) correctly characterizing the nature of
    their evidence?"\
    \
    This was on the newer form only

[^7]: My main complaint is in relying too much on point estimates, and
    not providing enough confidence-interval estimates for the more
    subtle results (beyond measurement of the overall average treatment
    effect).

[^8]: To what extent does the project contribute to the field or to
    practice, particularly in ways that are directly or indirectly
    relevant to global priorities and impactful interventions?

[^9]: I am not familiar enough with this field for my answer to matter.
    Based on what the authors claim, big contribution.

[^10]: The measurement of large spillover effects is really interesting.
     In future work, I would like to see the authors go into more detail
    on this analysis, because the spillovers seem surprisingly high
    (average indirect effect nearly 10x larger than the direct effect).
     I wonder how robust these results are to different choices of
    functional-form specification.  It might be fruitful to pursue the
    observed dominance of urban-to-rural spillovers. And if the indirect
    effects are really so much higher than the direct effects, I would
    love to know why that's the case.  Can we find direct, corroborating
    evidence that a huge number of people in the sample live in rural
    postal codes but work in nearby urban postal codes, for example?  I
    could imagine writing an entire paper to explore this phenomenon and
    better understand it.

[^11]: Are methods clearly justified and explained? Are methods and
    their underlying assumptions reasonable? Are the results likely to
    be robust to changes in the assumptions? Have the authors avoided
    bias and questionable research practices?

[^12]: The experimental design and analysis is well explained.

[^13]: Are concepts clearly defined? Is the reasoning transparent? Are
    conclusions consistent with the evidence (or formal proofs)
    presented? Are the data and/or analysis, including tables and
    figures, relevant to the argument?

[^14]: This paper is written much more clearly than the average academic
    paper. I like to think that I helped the authors achieve this
    positive outcome, as I was a referee on the paper at Management
    Science.

[^15]: Would another researcher be able to replicate the analysis? Are
    the method and its details explained sufficiently? Is the source of
    the data clear? Is the data made as widely available as possible,
    with clear labeling and explanation? Do the authors provide
    resources that are likely to enable future research and
    meta-analysis?

[^16]: I have not tried loading the data and running the authors' code,
    but I verified that it existed on the Management Science website.  
    I also find that the experimental design was described clearly
    enough that I could try to replicate it, with sufficient budget, on
    Facebook.

[^17]: Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic and relevant to practitioners?

[^18]: The latter ratings were merged in the newer form\
    \
    "Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?"

    "Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic? Do the authors report results that are relevant to
    practitioners? Do they provide useful quantified estimates (costs,
    benefits, etc.)?"

[^19]: These results help us understand more about how digital
    advertising really works, particularly in the realm of charitable
    fundraising.   Scholars learn important ideas from this paper about
    how to run more successful experiments to measure the effects of
    advertising, and charitable fundraisers learn ideas about whether
    Facebook advertising can be profitable as well as how they might
    improve their ad campaigns.

[^20]: Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?

[^21]: The latter ratings were merged in the newer form\
    \
    "Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?"

    "Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic? Do the authors report results that are relevant to
    practitioners? Do they provide useful quantified estimates (costs,
    benefits, etc.)?"

[^22]: This has already been published at Management Science.

[^23]: The evaluator was given the following instructions:\
    \
    Identify the most important and impactful factual claim this
    research makes -- e.g., a binary claim or a point estimate or
    prediction.

    Please state the authors' claim precisely and quantitatively.
    Identify the source of the claim (i.e., cite the paper), and briefly
    mention the evidence underlying this. We encourage you to explain
    why you believe this claim is important, either here, or in the text
    of your report.

[^24]: Evaluators were asked: To what extent do you \*believe\* the
    claim you stated above? Feel free to express this either a. in terms
    of the probability of the claim being true, b. as a credible
    interval for the parameter being estimated, or c. however you feel
    comfortable.

[^25]: *We asked:*

    \[Optional\] What additional information, evidence, replication, or
    robustness check would make you substantially more (or less)
    confident in this claim?

    Feel free to refer to the main body of your evaluation here; you
    don\'t need to repeat yourself. Please specify how you would perform
    this robustness check (etc.) as precisely as you are willing. E.g.,
    if you suggest a particular estimation command in a statistical
    package, this could be very helpful for future robustness
    replication work.

[^26]: *We asked:*\
    \
    \[Optional\] Identify the important \*implication\* of the above
    claim for funding and policy choices? To what extent do you
    \*believe\* this implication? How should it inform policy choices?\
    \
    Note: this 'implication' could be suggested by the evaluation
    manager in some cases. As an example of an \'implication\' \... in a
    global health context, the \'main claim\' might suggest that a
    vitamin supplement intervention, if scaled up, would save lives at a
    \$XXXX per life saved.

    We did not ask this in the 'applied stream' as it is most likely
    redundant.\
    \

[^27]: Tagat: "The paper could do more comprehensive statistical tests
    for pretreatment differences. While Table 1 shows no significant
    differences in Save the Children donations, this analysis is
    incomplete: (a) Table A2 is referenced but doesn\'t include p-values
    or clear difference tests; For competing charity analysis (Table
    A4), significant pretreatment differences are acknowledged,
    requiring difference-in-difference specifications; and (b) The
    crowding-out analysis reveals baseline imbalances that necessitate
    additional statistical controls."\
    \
    "Although the paper is already published (in a reputed journal), the
    study would benefit from addressing the pretreatment balance
    documentation, clarifying geographic measurement issues, and
    providing more detailed methodology for handling potential
    contamination effects."

[^28]: Tagat's notes: "The 30km radius for measuring spillovers seems to
    be coarse for an online platform study. This might be because
    spillovers in the online domain are especially difficult to track.
    Online sharing capabilities (video forwarding) could extend
    treatment effects beyond geographic boundaries, control group postal
    codes might receive shared content through social networks. Although
    the paper mentions \"forwarding button\" functionality, it doesn\'t
    adequately address cross-contamination between treatment and control
    areas".
