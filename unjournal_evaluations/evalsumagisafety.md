---
article:
  doi: 10.21428/d28e8e57.9b0d8cda
  elocation-id: evalsumagisafety
author:
- Evaluator 1
- Evaluator 2
- David Reinstein
- Lorenzo Pacchiardi
bibliography: /tmp/tmp-60jST6fCn5ZxID.json
copyright:
  link: "https://creativecommons.org/licenses/by/4.0/"
  text: Creative Commons Attribution 4.0 International License
  type: CC-BY
csl: /app/dist/server/server/utils/citations/citeStyles/apa-6th-edition.csl
date:
  day: 03
  month: 06
  year: 2025
journal:
  publisher-name: The Unjournal
  title: The Unjournal
link-citations: true
title: "Evaluation Summary and Metrics: \"Towards best practices in AGI
  safety and governance: A survey of expert opinion\" (\\~applied stream)"
uri: "https://unjournal.pubpub.org/pub/evalsumagisafety"
---

# Abstract 

We organized two evaluations of the paper: \"Towards best practices in
AGI safety and governance: A survey of expert opinion\"[@ndma3c4b4g7].
This paper "finds broad support for nearly all proposed safety practices
across AGI labs, governments, and civil society" (evaluator 1).
Evaluation 2 was done through our "applied and policy stream", described
[here](https://docs.google.com/document/d/1RwkmGJtaOcryK-tJs3mrs6DIAj411YRnsauaj6EE6WY/edit#heading=h.o7xzpvh0h0b2 "null"),
and involved a \~minor conflict of interest (see below). Both evaluators
rated the paper highly and found this work valuable and meaningful for
policy and discussions of AI safety. They also highlighted important
limitations (including sampling bias, classification of practices,
interpretation of results, and abstract agreement vs. real-world
implementation) and gave suggestions for improvement. To read these
evaluations, please see the links below.

# **Evaluations**

1\. [Evaluator
1](https://unjournal.pubpub.org/pub/e1agisafety/draft?access=l4dq53cd "null")

2\. [Evaluator
2](https://unjournal.pubpub.org/pub/e2agisafety/draft?access=iubxmm9e "null")

# **Overall ratings**

We asked evaluators to provide overall assessments as well as ratings
for a range of specific criteria. * *

**I. Overall assessment **(See footnote[^1])

**II. Journal rank tier, normative rating (0-5): **On a 'scale of
journals', what 'quality of journal' should this be published in?[^2]
*Note: 0= lowest/none, 5= highest/best. *

+---+-------------------+---+
|   | **Overall         | * |
|   | assessment        | * |
|   | (0-100)**         | J |
|   |                   | o |
|   |                   | u |
|   |                   | r |
|   |                   | n |
|   |                   | a |
|   |                   | l |
|   |                   | r |
|   |                   | a |
|   |                   | n |
|   |                   | k |
|   |                   | t |
|   |                   | i |
|   |                   | e |
|   |                   | r |
|   |                   | , |
|   |                   | n |
|   |                   | o |
|   |                   | r |
|   |                   | m |
|   |                   | a |
|   |                   | t |
|   |                   | i |
|   |                   | v |
|   |                   | e |
|   |                   | r |
|   |                   | a |
|   |                   | t |
|   |                   | i |
|   |                   | n |
|   |                   | g |
|   |                   | ( |
|   |                   | 0 |
|   |                   | - |
|   |                   | 5 |
|   |                   | ) |
|   |                   | * |
|   |                   | * |
+===+===================+===+
| E | 70                | 4 |
| v |                   | . |
| a |                   | 0 |
| l |                   |   |
| u |                   |   |
| a |                   |   |
| t |                   |   |
| o |                   |   |
| r |                   |   |
| 1 |                   |   |
+---+-------------------+---+
| E | 75\*\*[^3]        | N |
| v |                   | A |
| a |                   |   |
| l |                   |   |
| u |                   |   |
| a |                   |   |
| t |                   |   |
| o |                   |   |
| r |                   |   |
| 2 |                   |   |
+---+-------------------+---+

*See
"*[*Metrics*](https://unjournal.pubpub.org/pub/evalsumagisafety#metrics "null")*"
below for a more detailed breakdown of the evaluators' ratings across
several categories. To see these ratings in the context of all Unjournal
ratings, with some analysis, see our *[*data presentation
here.*](https://unjournal.github.io/unjournaldata/chapters/evaluation_data_analysis.html#basic-presentation "null")[^4]*
*

*See
*[*here*](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#metrics-overall-assessment-categories "null")*
for the current full evaluator guidelines, including further explanation
of the requested ratings.*

# Evaluation summaries

## Anonymous evaluator 1

This insightful and policy-relevant paper brings empirical grounding to
AGI safety measures by assessing expert consensus. It finds broad
support for nearly all proposed safety practices across AGI labs,
governments, and civil society. Key limitations \[of the paper\] include
potential sampling bias -- particularly over-representation of
safety-minded respondents -- and the challenge of interpreting abstract
agreement as indicative of real-world implementation. Still, the study
offers valuable input for policymakers and contributes meaningfully to
discussions on AGI safety.

## Anonymous evaluator 2

This paper makes a valuable contribution to AGI safety by identifying
areas of consensus in best practices, with implications for
standards-setting. While the methodology is rigorous, more justification
is needed for the selection and classification of the 50 practices.
Potential biases---particularly AGI labs endorsing their own
practices---should be better addressed. Organizing and contextualizing
practices more clearly would aid practitioners. The interpretation of
results should in some occasions be caveated with what the agreement
gathered itself affords, and avoid going beyond that. Overall, this
paper makes a great first step toward best practices for AGI and sets
the grounds for important future work on the topic.

# Metrics

## Ratings

[See
here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#quantitative-metrics "null")
for details on the categories below, and the guidance given to
evaluators.

+----------------------------------+--------------+----------+---------------+-----------+
|                                  | **Evaluator  |          | **Evaluator   |           |
|                                  | 1**          |          | 2\*\***       |           |
|                                  |              |          |               |           |
|                                  | Anonymous    |          | Anonymous     |           |
+==================================+==============+==========+===============+===========+
| **Rating category**              | **Rating     | **90% CI | **Rating      | **90% CI  |
|                                  | (0-100)**    | **       | (0-100)**     | **        |
|                                  |              |          |               |           |
|                                  |              | **(      |               | **        |
|                                  |              | 0-100)\* |               | (0-100)\* |
|                                  |              | **       |               | **        |
+----------------------------------+--------------+----------+---------------+-----------+
| Overall assessment[^5]           | 70           | (60, 80) | 75\*\*        | (65, 85)  |
+----------------------------------+--------------+----------+---------------+-----------+
| Claims, strength,                | 70           | (65, 75) | 80            | (70, 90)  |
| characterization of evidence[^6] |              |          |               |           |
+----------------------------------+--------------+----------+---------------+-----------+
| Advancing knowledge and          | 80           | (75, 85) | 70            | (60, 80)  |
| practice[^7]                     |              |          |               |           |
+----------------------------------+--------------+----------+---------------+-----------+
| Methods: Justification,          | 70           | (65, 75) | 70            | (60, 80)  |
| reasonableness, validity,        |              |          |               |           |
| robustness[^8]                   |              |          |               |           |
+----------------------------------+--------------+----------+---------------+-----------+
| Logic & communication[^9]        | 85           | (80, 90) | 80            | (70, 90)  |
+----------------------------------+--------------+----------+---------------+-----------+
| Open, collaborative,             | 65           | (50, 80) | 80            | (70, 90)  |
| replicable[^10]                  |              |          |               |           |
+----------------------------------+--------------+----------+---------------+-----------+
| Real-world relevance [^11],[^12] | 90           | (80,     | 70            | (60, 80)  |
|                                  |              | 100)     |               |           |
+----------------------------------+--------------+----------+---------------+-----------+
| Relevance to global              | 90           | (80,     | 70            | (60, 80)  |
| priorities[^13], [^14]           |              | 100)     |               |           |
+----------------------------------+--------------+----------+---------------+-----------+

\*\*COI issue: Evaluator 2 is a co-author with the first author in a
paper with over ten authors.  Due to their recent work engagements, they
also have some professional ties with at least two of the other
co-authors.

## Journal ranking tiers

[See
here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers "null")
for more details on these tiers.

+-------------------------------+-------------+--------------------------------+
|                               | **Evaluator |                                |
|                               | 1**         |                                |
|                               |             |                                |
|                               | Anonymous   |                                |
+===============================+=============+================================+
| **Judgment**                  | **Ranking   | **90% CI **                    |
|                               | tier        |                                |
|                               | (0-5)**     |                                |
+-------------------------------+-------------+--------------------------------+
| On a 'scale of journals',     | 4.0         | (3.5, 4.5)                     |
| what 'quality of journal'     |             |                                |
| *should* this be published    |             |                                |
| in?                           |             |                                |
+-------------------------------+-------------+--------------------------------+
| What 'quality journal' do you | 3.5         | (3.1, 4.0)                     |
| expect this work *will* be    |             |                                |
| published in?                 |             |                                |
+-------------------------------+-------------+--------------------------------+
| [See                          | *We         |                                |
| here](https://                | summarize   |                                |
| globalimpact.gitbook.io/the-u | these as:*  |                                |
| njournal-project-and-communic |             |                                |
| ation-space/policies-projects | -   0.0:    |                                |
| -evaluation-workflow/evaluati |             |                                |
| on/guidelines-for-evaluators# |  Marginally |                                |
| journal-ranking-tiers "null") |     respect |                                |
| for more details on these     | able/Little |                                |
| tiers.                        |     to no   |                                |
|                               |     value   |                                |
|                               |             |                                |
|                               | -   1.0:    |                                |
|                               |             |                                |
|                               | OK/Somewhat |                                |
|                               |             |                                |
|                               |    valuable |                                |
|                               |             |                                |
|                               | -   2.0:    |                                |
|                               |             |                                |
|                               |    Marginal |                                |
|                               |     B-jou   |                                |
|                               | rnal/Decent |                                |
|                               |     field   |                                |
|                               |     journal |                                |
|                               |             |                                |
|                               | -   3.0:    |                                |
|                               |     Top     |                                |
|                               |     B-jou   |                                |
|                               | rnal/Strong |                                |
|                               |     field   |                                |
|                               |     journal |                                |
|                               |             |                                |
|                               | -   4.0:    |                                |
|                               |             |                                |
|                               |    Marginal |                                |
|                               |     A-      |                                |
|                               | Journal/Top |                                |
|                               |     field   |                                |
|                               |     journal |                                |
|                               |             |                                |
|                               | -   5.0:    |                                |
|                               |     A-      |                                |
|                               | journal/Top |                                |
|                               |     journal |                                |
+-------------------------------+-------------+--------------------------------+

# Claim identification and assessment (summary)

For *the full discussions, see the* *corresponding sections in each
linked evaluation.*

+-------------------+----------------------------------------------+--------------------------------+
|                   | **Main research claim**[^15]                 | **Belief in claim**[^16]       |
+===================+==============================================+================================+
| **Evaluator 1     | That a majority of AGI governance experts    | I fully believe the claims     |
| **Anonymous       | exhibit consensus in supporting 49 out of 50 | presented (over 90%            |
|                   | specific safety-related policies and         | probability of the claim being |
|                   | practices.                                   | true).                         |
+-------------------+----------------------------------------------+--------------------------------+

# Evaluation manager's discussion, our process

## Conflict of Interest

Evaluator 2 is a co-author with the first author in a paper with over
ten authors.  Due to their recent work engagements, they also have some
professional ties with at least two of the other co-authors.'

## Issues meriting further evaluation (or consideration in future work

A number of issues were raised in the bespoke evaluation notes that were
not discussed (much) by the evaluators and might be worthy of further
evaluation, or of consideration by the authors and future researchers in
designing follow-up work. These include:

-   *Question design* (acquiescence bias, priming, order effects, etc.;
    reverse coding and other potential remedied)

-   Patterns of *non*-response to certain questions

-   Was the survey set up to provide strong 'value of information'
    (considering likely prior beliefs, and costs and benefits of safety
    practices)?

-   If the paper is largely about "demonstrating a case that AI people
    agree on this to regulators" we might want to encourage a
    red-teaming approach to this

-   *Lack of prioritisation or ranking between questions*: Experts
    evaluate each statement independently, without providing numerical
    scores for effectiveness, making it impossible to compare and
    prioritize various proposals. For example, more people might believe
    that Proposal A should be implemented than Proposal B, yet all of
    those who support both may consider Proposal B to be more impactful
    than Proposal A. This nuance is not captured in the current
    approach. Could or should this be addressed in the future?

## Why we chose this paper  

From our prioritization notes:

> This paper aims to survey the opinions of 50 leading experts on 50
> potential best practices to promote AGI safety and governance. Experts
> rated each potential statement on a 5 point Likert scale. Experts
> broadly support all practices listed, although some receive higher
> mean ratings and have lower disagreement.
>
> The paper has received a moderate amount of attention (21 citations
> and GovAI is a large player in the AI governance space). \
> \
> Extensively mentioned at [Long list of AI questions --- EA
> Forum](https://forum.effectivealtruism.org/posts/giKoHZfmSvvKyNT2R/long-list-of-ai-questions "null")
>
> This is the kind of paper that I think could benefit from review from
> social scientists.

## How we chose the evaluators

We looked for (and found) evaluators with both survey methods/social
science expertise and contextual understanding of the AGI safety issues.
We also sought balance in terms of the evaluators' known positions on
the 'severity of AI safety concerns' question. (We further discuss what
we were looking for in evaluators in the shared ["bespoke
notes"](https://docs.google.com/document/d/1kHWQat26j1alwX-ef3hu2Wh_BnMlF2BNzK_DU5RF3lQ/edit?tab=t.0#heading=h.7havg98i8l3f "null").)

## Evaluation process

We shared [these "bespoke
notes"](https://docs.google.com/document/d/1kHWQat26j1alwX-ef3hu2Wh_BnMlF2BNzK_DU5RF3lQ/edit?tab=t.0#heading=h.7havg98i8l3f "null")
with the evaluators, including some suggestions on issues they may wish
to focus on.

The authors were kept informed about the process, but declined to
respond ("we\'re unusually busy at the moment"). As always, if they
choose to respond in future, we will incorporate their response in this
package.

## Other relevant work

We refer readers to a recent work with a similar spirit to the one
evaluated here
(<https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5021463>), which
provides complementary insights. That work focuses on measures to
mitigate systemic risks associated with general-purpose AI models,
rather than addressing the AGI scenario considered in this paper, though
some of the proposed measures partially overlap.

##  {#r6902555554}

# References

1\. Schuett, J., Dreksler, N., Anderljung, M., McCaffary, D., Heim, L.,
Bluemke, E., & Garfinkel, B. (2023). Towards best practices in AGI
safety and governance: A survey of expert opinion. arXiv:2305.07153.
https://doi.org/10.48550/arXiv.2305.07153

[^1]: We asked them to rank this paper "heuristically" as a percentile
    "relative to all serious research in the same area that you have
    encountered in the last three years." We requested they "consider
    all aspects of quality, credibility, importance to knowledge
    production, and importance to practice.

[^2]: See ranking tiers discussed
    [here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers).

[^3]: COI issue: Evaluator 2 is a co-author with the first author in a
    paper with over ten authors.  Due to their recent work engagements,
    they also have some professional ties with at least two of the other
    co-authors.

[^4]: Note: if you are reading this before, or soon after this has been
    publicly released, the ratings from this paper may not yet have been
    incorporated into that data presentation.

[^5]: Judge the quality of the research heuristically. Consider all
    aspects of quality, credibility, importance to knowledge production,
    and importance to practice.

[^6]: "Do the authors do a good job of (i) stating their main questions
    and claims, (ii) providing strong evidence and powerful approaches
    to inform these, and (iii) correctly characterizing the nature of
    their evidence?"\
    \
    This was on the newer form only

[^7]: To what extent does the project contribute to the field or to
    practice, particularly in ways that are directly or indirectly
    relevant to global priorities and impactful interventions?

[^8]: Are methods clearly justified and explained? Are methods and their
    underlying assumptions reasonable? Are the results likely to be
    robust to changes in the assumptions? Have the authors avoided bias
    and questionable research practices?

[^9]: Are concepts clearly defined? Is the reasoning transparent? Are
    conclusions consistent with the evidence (or formal proofs)
    presented? Are the data and/or analysis, including tables and
    figures, relevant to the argument?

[^10]: Would another researcher be able to replicate the analysis? Are
    the method and its details explained sufficiently? Is the source of
    the data clear? Is the data made as widely available as possible,
    with clear labeling and explanation? Do the authors provide
    resources that are likely to enable future research and
    meta-analysis?

[^11]: Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic and relevant to practitioners?

[^12]: The latter ratings were merged in the newer form\
    \
    "Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?"

    "Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic? Do the authors report results that are relevant to
    practitioners? Do they provide useful quantified estimates (costs,
    benefits, etc.)?"

[^13]: Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?

[^14]: The latter ratings were merged in the newer form\
    \
    "Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?"

    "Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic? Do the authors report results that are relevant to
    practitioners? Do they provide useful quantified estimates (costs,
    benefits, etc.)?"

[^15]: The evaluator was given the following instructions:\
    \
    Identify the most important and impactful factual claim this
    research makes -- e.g., a binary claim or a point estimate or
    prediction.

    Please state the authors' claim precisely and quantitatively.
    Identify the source of the claim (i.e., cite the paper), and briefly
    mention the evidence underlying this. We encourage you to explain
    why you believe this claim is important, either here, or in the text
    of your report.

[^16]: Evaluators were asked: To what extent do you \*believe\* the
    claim you stated above? Feel free to express this either a. in terms
    of the probability of the claim being true, b. as a credible
    interval for the parameter being estimated, or c. however you feel
    comfortable.
