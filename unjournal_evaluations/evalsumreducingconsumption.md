---
affiliation:
- id: 0
  organization: University of Connecticut
article:
  doi: 10.21428/d28e8e57.808d24c9
  elocation-id: evalsumreducingconsumption
author:
- Evaluator 1
- Matthew B. Jané
- David Reinstein
- Tabare Capitan
bibliography: /tmp/tmp-55unRfE6vi0RDg.json
copyright:
  link: "https://creativecommons.org/licenses/by/4.0/"
  text: Creative Commons Attribution 4.0 International License
  type: CC-BY
csl: /app/dist/server/server/utils/citations/citeStyles/apa-6th-edition.csl
date:
  day: 24
  month: 07
  year: 2025
journal:
  publisher-name: The Unjournal
  title: The Unjournal
link-citations: true
title: "Evaluation Summary and Metrics: \"Meaningfully reducing
  consumption of meat and animal products is an unsolved problem: A
  meta-analysis\""
uri: "https://unjournal.pubpub.org/pub/evalsumreducingconsumption"
---

# Abstract 

We organized two evaluations of the paper: "Meaningfully reducing
consumption of meat and animal products is an unsolved problem: A
meta-analysis"[@npkfxe8afa9]. Both evaluators offer some praise (of the
importance of the topic and the transparent reporting), but they are
critical on the whole, while offering substantive suggestions for
improvement, emphazizing a more *systematic* approach. Their concerns
include the transparency, design logic, and robustness of the paper's
methods---particularly in relation to its search strategy and inclusion
criteria, outcome selection, and handling of missing data. Jané
highlights guesswork/approximation in effect size coding, ignoring
imputation variance, and neglecting key sources of study bias (such as
selective outcome reporting). To read these evaluations, please see the
links below.

## **Evaluations**

1\. [Evaluator
1](https://unjournal.pubpub.org/pub/e1reducingconsumption/draft?access=ziq3yhc6 "null")

2\. [Matthew B.
Jané](https://unjournal.pubpub.org/pub/e2reducingconsumption/draft?access=4v3s93k1 "null")

## Author response

-   [Author's response (Seth Ariel
    Green)](https://unjournal.pubpub.org/pub/aflv6m1e/ "null")

# **Overall ratings**

We asked evaluators to provide overall assessments as well as ratings
for a range of specific criteria. * *

**I. Overall assessment **(See footnote[^1])

**II. Journal rank tier, normative rating (0-5): **On a 'scale of
journals', what 'quality of journal' should this be published in?[^2]
*Note: 0= lowest/none, 5= highest/best. *

+---+-------------------+---+
|   | **Overall         | * |
|   | assessment        | * |
|   | (0-100)**         | J |
|   |                   | o |
|   |                   | u |
|   |                   | r |
|   |                   | n |
|   |                   | a |
|   |                   | l |
|   |                   | r |
|   |                   | a |
|   |                   | n |
|   |                   | k |
|   |                   | t |
|   |                   | i |
|   |                   | e |
|   |                   | r |
|   |                   | , |
|   |                   | n |
|   |                   | o |
|   |                   | r |
|   |                   | m |
|   |                   | a |
|   |                   | t |
|   |                   | i |
|   |                   | v |
|   |                   | e |
|   |                   | r |
|   |                   | a |
|   |                   | t |
|   |                   | i |
|   |                   | n |
|   |                   | g |
|   |                   | ( |
|   |                   | 0 |
|   |                   | - |
|   |                   | 5 |
|   |                   | ) |
|   |                   | * |
|   |                   | * |
+===+===================+===+
| E | 75                | 3 |
| v |                   | . |
| a |                   | 5 |
| l |                   |   |
| u |                   |   |
| a |                   |   |
| t |                   |   |
| o |                   |   |
| r |                   |   |
| 1 |                   |   |
+---+-------------------+---+
| M | 39                | 1 |
| a |                   | . |
| t |                   | 1 |
| t |                   |   |
| h |                   |   |
| e |                   |   |
| w |                   |   |
| B |                   |   |
| . |                   |   |
| J |                   |   |
| a |                   |   |
| n |                   |   |
| é |                   |   |
+---+-------------------+---+

*See
"*[*Metrics*](https://unjournal.pubpub.org/pub/alatasevalsum/release/9#metrics-all-evaluators "null")*"
below for a more detailed breakdown of the evaluators' ratings across
several categories. To see these ratings in the context of all Unjournal
ratings, with some analysis, see our *[*data presentation
here.*](https://unjournal.github.io/unjournaldata/chapters/evaluation_data_analysis.html#basic-presentation "null")[^3]*
*

*See
*[*here*](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#metrics-overall-assessment-categories "null")*
for the current full evaluator guidelines, including further explanation
of the requested ratings.*

# Evaluation summaries

## Anonymous evaluator 1

This is a strong statistical analysis of the literature on meat and
animal product consumption. It shows weaker evidence than previous
reviews, purportedly because of a stricter set of criteria for inclusion
which focused on RCTs. The authors have not followed standard methods
for systematic reviews, basing their analysis on previous meta-analyses
with which they were familiar. They searched Google Scholar, not in fact
a bibliographic database, in place of traditional databases like Scopus,
Web of Science Core Collections, CAB Abstracts, etc. I do feel there's a
strong likelihood studies have been missed. The authors also fail to
conduct important checks of consistency in screening, data extraction
and appraisal of risk of bias. Their risk of bias assessment also seems
less robust than standard approaches in evidence synthesis using
peer-reviewed tools.

## Matthew B. Jané {#matthew-b-jan}

Strengths: The study is highly transparent, with fully reproducible code
and open data. The analytic pipeline is well-documented and is an
excellent example of open science.\
\
Limitations: However, major methodological issues undermine the study\'s
validity. These include improper missing data handling, unnecessary
exclusion of small studies, extensive guessing in effect size coding,
lacking a serious risk-of-bias assessment, and excluding all-but-one
outcome per study. Overall, the transparency is strong, but the
underlying analytic quality is limited.

# Metrics

## Ratings

[See
here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#quantitative-metrics "null")
for details on the categories below, and the guidance given to
evaluators.

+--------------------+--------------+----------+-----------------------+---------------+----------+
|                    | **Evaluator  |          |                       | **Evaluator   |          |
|                    | 1**          |          |                       | 2**           |          |
|                    |              |          |                       |               |          |
|                    | Anonymous    |          |                       | Matthew B.    |          |
|                    |              |          |                       | Jané          |          |
+====================+==============+==========+=======================+===============+==========+
| **Rating           | **Rating     | **90% CI | **Comments **         | **Rating      | **90% CI |
| category**         | (0-100)**    | **       |                       | (0-100)**     | **       |
|                    |              |          |                       |               |          |
|                    |              | *        |                       |               | *        |
|                    |              | *(0-100) |                       |               | *(0-100) |
|                    |              | **       |                       |               | **       |
+--------------------+--------------+----------+-----------------------+---------------+----------+
| Overall            | 75           | (60, 80) | Generally probably    | 39            | (14, 62) |
| assessment[^4]     |              |          | good                  |               |          |
+--------------------+--------------+----------+-----------------------+---------------+----------+
| Claims, strength,  | 60           | (50, 70) | Methodological        | 59            | (30, 85) |
| characterization   |              |          | problems lower        |               |          |
| of evidence[^5]    |              |          | \[i.e., reduce\]      |               |          |
|                    |              |          | strength of           |               |          |
|                    |              |          | conclusions           |               |          |
+--------------------+--------------+----------+-----------------------+---------------+----------+
| Advancing          | 60           | (50, 70) | Interesting           | 50            | (5, 95)  |
| knowledge and      |              |          | conclusions but       |               |          |
| practice[^6]       |              |          | unreliable given      |               |          |
|                    |              |          | methodological flaws  |               |          |
+--------------------+--------------+----------+-----------------------+---------------+----------+
| Methods:           | 40           | (30, 50) | Poor methodology      | 25            | (10, 43) |
| Justification,     |              |          | beyond statistics     |               |          |
| reasonableness,    |              |          |                       |               |          |
| validity,          |              |          |                       |               |          |
| robustness[^7]     |              |          |                       |               |          |
+--------------------+--------------+----------+-----------------------+---------------+----------+
| Logic &            | 80           | (70, 90) | Excellently written,  | 40            | (19, 65) |
| communication[^8]  |              |          | very clear, logical   |               |          |
+--------------------+--------------+----------+-----------------------+---------------+----------+
| Open,              | 70           | (60, 80) | Strong, but needs a   | 91            | (86,     |
| collaborative,     |              |          | lot more data in line |               | 100)     |
| replicable[^9]     |              |          | with evidence         |               |          |
|                    |              |          | synthesis standards   |               |          |
+--------------------+--------------+----------+-----------------------+---------------+----------+
| Real-world         | 90           | (80,     | This is vital stuff,  | 88            | (45, 93) |
| relevance          |              | 100)     | just do it right, the |               |          |
| [^10],[^11]        |              |          | robust methods are    |               |          |
|                    |              |          | there for your        |               |          |
|                    |              |          | protection            |               |          |
+--------------------+--------------+----------+-----------------------+---------------+----------+
| Relevance to       | 90           | (80,     |                       | 88            | (45, 93) |
| global             |              | 100)     |                       |               |          |
| priorities[^12],   |              |          |                       |               |          |
| [^13]              |              |          |                       |               |          |
+--------------------+--------------+----------+-----------------------+---------------+----------+

## Journal ranking tiers

[See
here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers "null")
for more details on these tiers.

+-------------------------------+-------------+---------+-----------+-----------+---------------+
|                               | **Evaluator |         |           | **        |               |
|                               | 1**         |         |           | Evaluator |               |
|                               |             |         |           | 2**       |               |
|                               | Anonymous   |         |           |           |               |
|                               |             |         |           | Matthew   |               |
|                               |             |         |           | B. Jané   |               |
+===============================+=============+=========+===========+===========+===============+
| **Judgment**                  | **Ranking   | **90%   | **C       | **Ranking | **90% CI **   |
|                               | tier        | CI **   | omments** | tier      |               |
|                               | (0-5)**     |         |           | (0-5)**   |               |
+-------------------------------+-------------+---------+-----------+-----------+---------------+
| On a 'scale of journals',     | 3.5         | (3.0,   | [^14]     | 1.1       | (0.4, 1.9)    |
| what 'quality of journal'     |             | 4.0)    |           |           |               |
| *should* this be published    |             |         |           |           |               |
| in?                           |             |         |           |           |               |
+-------------------------------+-------------+---------+-----------+-----------+---------------+
| What 'quality journal' do you | 4.0         | (3.5,   | [^15]     | 3.2       | (2.3, 4.1)    |
| expect this work *will* be    |             | 4.5)    |           |           |               |
| published in?                 |             |         |           |           |               |
+-------------------------------+-------------+---------+-----------+-----------+---------------+
| [See                          | *We         |         |           |           |               |
| here](https://                | summarize   |         |           |           |               |
| globalimpact.gitbook.io/the-u | these as:*  |         |           |           |               |
| njournal-project-and-communic |             |         |           |           |               |
| ation-space/policies-projects | -   0.0:    |         |           |           |               |
| -evaluation-workflow/evaluati |             |         |           |           |               |
| on/guidelines-for-evaluators# |  Marginally |         |           |           |               |
| journal-ranking-tiers "null") |     respect |         |           |           |               |
| for more details on these     | able/Little |         |           |           |               |
| tiers.                        |     to no   |         |           |           |               |
|                               |     value   |         |           |           |               |
|                               |             |         |           |           |               |
|                               | -   1.0:    |         |           |           |               |
|                               |             |         |           |           |               |
|                               | OK/Somewhat |         |           |           |               |
|                               |             |         |           |           |               |
|                               |    valuable |         |           |           |               |
|                               |             |         |           |           |               |
|                               | -   2.0:    |         |           |           |               |
|                               |             |         |           |           |               |
|                               |    Marginal |         |           |           |               |
|                               |     B-jou   |         |           |           |               |
|                               | rnal/Decent |         |           |           |               |
|                               |     field   |         |           |           |               |
|                               |     journal |         |           |           |               |
|                               |             |         |           |           |               |
|                               | -   3.0:    |         |           |           |               |
|                               |     Top     |         |           |           |               |
|                               |     B-jou   |         |           |           |               |
|                               | rnal/Strong |         |           |           |               |
|                               |     field   |         |           |           |               |
|                               |     journal |         |           |           |               |
|                               |             |         |           |           |               |
|                               | -   4.0:    |         |           |           |               |
|                               |             |         |           |           |               |
|                               |    Marginal |         |           |           |               |
|                               |     A-      |         |           |           |               |
|                               | Journal/Top |         |           |           |               |
|                               |     field   |         |           |           |               |
|                               |     journal |         |           |           |               |
|                               |             |         |           |           |               |
|                               | -   5.0:    |         |           |           |               |
|                               |     A-      |         |           |           |               |
|                               | journal/Top |         |           |           |               |
|                               |     journal |         |           |           |               |
+-------------------------------+-------------+---------+-----------+-----------+---------------+

# Claim identification and assessment (summary)

For *the full discussions, see the* *corresponding sections in each
linked evaluation.*

+----------------+-----------------------------------------+----------------------------------------+------------------------------------------------+-------------------------+
|                | **Main research claim**[^16]            | **Belief in claim**[^17]               | **Suggested robustness checks**[^18]           | ** Important            |
|                |                                         |                                        |                                                | 'implication', policy,  |
|                |                                         |                                        |                                                | credibility**[^19]      |
+================+=========================================+========================================+================================================+=========================+
| **Evaluator 1  | Claim: Meat and animal product          | Belief/confidence: It's hard to say    | Conduct searches in Scopus, WoSCC and CAB      | Policy/funding          |
| **Anonymous    | reduction interventions don't seem to   | given the methods used-maybe they      | abstracts to see what search results           | implication: Impossible |
|                | be as effective as previously suggested | missed some important studies, maybe   | overlapped and what you might have missed.     | to say with the level   |
|                | by evidence synthesis.                  | they still included some that were not | Provide cross checking tests of screening,     | of reliability I have.  |
|                |                                         | robust.                                | data extraction, and critical appraisal.       | It looks great, but I   |
|                |                                         |                                        | Provide more details on appraisal of Risk of   | don't really trust your |
|                |                                         |                                        | Bias. Include a PRISMA/ROSES checklist.        | methods.                |
+----------------+-----------------------------------------+----------------------------------------+------------------------------------------------+-------------------------+
| **Evaluator 2  | "We conclude that while existing        | I agree with the claim because this is | Obtain all relevant outcomes and studies (not  | N/A                     |
| **Matthew B.   | approaches do not provide a proven      | all I have read on this topic and it   | filtered by sample size \<25). Work with a     |                         |
| Jané           | remedy to MAP consumption, designs and  | does not appear that the evidence of   | librarian to make a supplementary systematic   |                         |
|                | measurement strategies have generally   | effectiveness (or ineffectiveness) is  | search to ensure good coverage. Use proper     |                         |
|                | been improving over time, and many      | very compelling.                       | missing data methods for non-significant and   |                         |
|                | promising interventions await rigorous  |                                        | unreported effects. Add a rigorous             |                         |
|                | evaluation."                            |                                        | risk-of-bias assessment that includes glaring  |                         |
|                |                                         |                                        | issues.                                        |                         |
+----------------+-----------------------------------------+----------------------------------------+------------------------------------------------+-------------------------+

# Evaluation managers' discussion 

*This discussion was mostly written by Tabare Capitan, with content from
David Reinstein where indicated*

This paper received two critical and methodologically informed
evaluations from researchers with substantial experience in quantitative
research synthesis. The evaluators identified a range of concerns
regarding the transparency, design logic, and robustness of the paper's
methods---particularly in relation to its search strategy, outcome
selection, and handling of missing data. Their critiques reflect a
broader tension within the field: while meta-analysis is often treated
as a gold standard for evidence aggregation, it remains highly sensitive
to subjective decisions at multiple stages.

Both evaluations highlight issues with transparency in search
strategies, subjective coding decisions, and the treatment of missing or
ambiguous data. Importantly, the authors themselves acknowledge many of
these concerns, including the resource constraints that shaped the final
design. Across the evaluations and the author response, there is broad
agreement on a central point: that a high degree of researcher judgment
was involved throughout the study. Again, this may reflect an important
feature of synthesis work beyond the evaluated paper---namely, that even
quantitative syntheses often rest on assumptions and decisions that are
not easily separable from the analysts\' own interpretive frameworks.
These shared acknowledgements may suggest that the field currently faces
limits in its ability to produce findings with the kind of objectivity
and replicability expected in other domains of empirical science.[^20]

We also note that one of the evaluators chose to forgo anonymity in
submitting their review. While The Unjournal permits reviewers to remain
anonymous, we support transparency when reviewers feel comfortable
sharing their identity. In this case, the decision may be seen as an act
of professional integrity and confidence in open scientific debate,
particularly given the potential reputational asymmetries involved in
critiquing work by more senior scholars.

> *David Reinstein: *I think I'm more optimistic than Tabaré about the
> potential for meta-analysis. I'm deeply convinced that there are large
> gains from trying to *systematically* combine evidence across papers,
> and even (carefully) across approaches and outcomes. Yes, there are
> deep methodological differences over the best approaches. But I
> believe that appropriate meta-analysis will yield more reliable
> understanding than ad-hoc approaches like 'picking a single best
> study' or 'giving one's intuitive impressions based on reading'.
> Meta-analysis could be made more reliable through robustness-checking,
> estimating a range of bounded estimates under a wide set of reasonable
> choices, and enabling data and dashboards for multiverse analysis,
> replication, and extensions.
>
> I believe a key obstacle to this careful, patient, open work is the
> current system of incentives and tools offered by academia and the
> current system of traditional journal publications as a career outcome
> an 'end state'. The author's response "But at some point, you declare
> a paper 'done' and submit it" exemplifies this challenge.\
> \
> The Unjournal aims to build and facilitate a better system. The
> author's response offers some thoughts about how others might follow
> this up. \"If anyone reading this wants to run any further extensions,
> and you have any questions about how to go about it, my email is in
> the paper and I'd be glad to hear from you\"\...\"\...please conduct
> the analysis, we'd love to read it\". We'd like to help facilitate and
> encourage such work.

##  Why We Chose This Paper 

This paper was selected in part due to the high level of attention it
has received in communities focused on animal welfare and effective
altruism. \>

> *David Reinstein*: See especially [this
> post](https://forum.effectivealtruism.org/posts/i5wnzz4uAgeF3ZRc5/meaningfully-reducing-meat-consumption-is-an-unsolved "null")
> on the EA forum. EA organizations have mainly focused *away from *the
> sorts of \~persuasive behavioral animal welfare interventions covered
> in this paper, in favor of other approaches to improving farmed animal
> welfare (e.g., see Open Philanthropy's grants in this area
> [here](https://www.openphilanthropy.org/grants/?q=&focus-area%5B%5D=farm-animal-welfare "null").)

It addresses a consequential and policy-relevant question---how
interventions may reduce meat consumption---through a structured
synthesis of existing literature. Although meta-analyses are sometimes
treated as endpoints in a research chain, we viewed this project as an
opportunity to evaluate the strength of the synthesis itself,
particularly as such studies often play an outsized role in shaping
public discourse and policy. The work also aligns with The Unjournal's
mission to support rigorous and transparent research on important social
topics. We hoped the evaluation process would clarify the strengths and
limitations of this particular synthesis while also contributing to
methodological reflection in the broader field.

> *David Reinstein*: Meta-analysis seems particularly challenging in
> this context, even conceptually. It is not clear to me here what the
> \"average effect\" across studies and interventions means or what
> it\'s useful for. I\'m more familiar with study-specific random
> effects for meta-analyses where each of the studies is fundamentally
> considering the same intervention and the same outcome. Jané requests
> a focus on "Prediction intervals \[to\] communicate the range of
> likely effects in future studies." The author's response notes " the
> paper advances a distinct vision of what meta-analysis is for, and how
> to conduct it, that bears further motivation and explanation. I'll
> start to do that here, but I think it calls for a separate methods
> note/paper." I think this merits further discussion.

## Evaluation Process 

Two evaluators were selected through our standard process, with a focus
on research experience, methodological competence, and domain relevance.
We prioritized methodological expertise over domain expertise (in
strategies to reduce meat consumption). Each evaluator considered both
the paper's methodological innovations and its departures from standard
practice. The feedback was shared with the authors, who then provided a
comprehensive public response. The author's reply elaborates on their
rationale for several non-standard choices, emphasizes the challenges of
conducting such work without substantial resources, and highlights the
considerable effort invested in transparency and reproducibility.

The exchange between authors and evaluators is collegial but pointed,
and may serve as a useful case study of both the potential and the
limits of current synthesis practices.

Finally, we note that it was difficult to find evaluators with the right
expertise to evaluate this work --- particularly at the intersection of
this topic (animal product consumption and behavioral interventions) and
these methods. We ended up focusing on *methodological* expertise
(although E1 has some adjacent links to the topic). Indeed, this may be
a relatively neglected field, and building and funding more expertise
may be highly valuable.

# References

1\. Green, S. A., Smith, A. B., & Mathur, M. B. (2025). Meaningfully
reducing consumption of meat and animal products is an unsolved problem:
A meta-analysis. \*Appetite\*, 216, 108233.
https://doi.org/10.1016/j.appet.2025.108233

[^1]: We asked them to rank this paper "heuristically" as a percentile
    "relative to all serious research in the same area that you have
    encountered in the last three years." We requested they "consider
    all aspects of quality, credibility, importance to knowledge
    production, and importance to practice.

[^2]: See ranking tiers discussed
    [here](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#journal-ranking-tiers).

[^3]: Note: if you are reading this before, or soon after this has been
    publicly released, the ratings from this paper may not yet have been
    incorporated into that data presentation.

[^4]: Judge the quality of the research heuristically. Consider all
    aspects of quality, credibility, importance to knowledge production,
    and importance to practice.

[^5]: "Do the authors do a good job of (i) stating their main questions
    and claims, (ii) providing strong evidence and powerful approaches
    to inform these, and (iii) correctly characterizing the nature of
    their evidence?"\
    \
    This was on the newer form only

[^6]: To what extent does the project contribute to the field or to
    practice, particularly in ways that are directly or indirectly
    relevant to global priorities and impactful interventions?

[^7]: Are methods clearly justified and explained? Are methods and their
    underlying assumptions reasonable? Are the results likely to be
    robust to changes in the assumptions? Have the authors avoided bias
    and questionable research practices?

[^8]: Are concepts clearly defined? Is the reasoning transparent? Are
    conclusions consistent with the evidence (or formal proofs)
    presented? Are the data and/or analysis, including tables and
    figures, relevant to the argument?

[^9]: Would another researcher be able to replicate the analysis? Are
    the method and its details explained sufficiently? Is the source of
    the data clear? Is the data made as widely available as possible,
    with clear labeling and explanation? Do the authors provide
    resources that are likely to enable future research and
    meta-analysis?

[^10]: Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic and relevant to practitioners?

[^11]: The latter ratings were merged in the newer form\
    \
    "Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?"

    "Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic? Do the authors report results that are relevant to
    practitioners? Do they provide useful quantified estimates (costs,
    benefits, etc.)?"

[^12]: Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?

[^13]: The latter ratings were merged in the newer form\
    \
    "Are the paper's chosen topic and approach likely to be useful to
    global priorities, cause prioritization, and high-impact
    interventions?"

    "Does the paper consider real-world relevance and deal with policy
    and implementation questions? Are the setup, assumptions, and focus
    realistic? Do the authors report results that are relevant to
    practitioners? Do they provide useful quantified estimates (costs,
    benefits, etc.)?"

[^14]: At present it's OK but if it were methodologically improved
    (mostly in clarity without much morework) it would be excellent

[^15]: Most of the time, methodological flaws are ignored and people
    just end up publishing elsewhere. Sigh.

[^16]: The evaluator was given the following instructions:\
    \
    Identify the most important and impactful factual claim this
    research makes -- e.g., a binary claim or a point estimate or
    prediction.

    Please state the authors' claim precisely and quantitatively.
    Identify the source of the claim (i.e., cite the paper), and briefly
    mention the evidence underlying this. We encourage you to explain
    why you believe this claim is important, either here, or in the text
    of your report.

[^17]: Evaluators were asked: To what extent do you \*believe\* the
    claim you stated above? Feel free to express this either a. in terms
    of the probability of the claim being true, b. as a credible
    interval for the parameter being estimated, or c. however you feel
    comfortable.

[^18]: *We asked:*

    \[Optional\] What additional information, evidence, replication, or
    robustness check would make you substantially more (or less)
    confident in this claim?

    Feel free to refer to the main body of your evaluation here; you
    don\'t need to repeat yourself. Please specify how you would perform
    this robustness check (etc.) as precisely as you are willing. E.g.,
    if you suggest a particular estimation command in a statistical
    package, this could be very helpful for future robustness
    replication work.

[^19]: *We asked:*\
    \
    \[Optional\] Identify the important \*implication\* of the above
    claim for funding and policy choices? To what extent do you
    \*believe\* this implication? How should it inform policy choices?\
    \
    Note: this 'implication' could be suggested by the evaluation
    manager in some cases. As an example of an \'implication\' \... in a
    global health context, the \'main claim\' might suggest that a
    vitamin supplement intervention, if scaled up, would save lives at a
    \$XXXX per life saved.

    We did not ask this in the 'applied stream' as it is most likely
    redundant.\
    \

[^20]:
