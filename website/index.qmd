---
title: "The Unjournal data blog"
image: logo.png
about:
  template: marquee
  links:
    - icon: github
      text: Github
      href: https://github.com/unjournal/unjournaldata
    - text: Posts
      href: posts.html 
aliases: 
  - chapters/evaluation_data_analysis.html
---

[The Unjournal](https://www.unjournal.org) coordinates the public evaluation of 
papers and research projects. We are working independently of traditional academic 
journals to build an open platform and a sustainable system for feedback, ratings, 
and assessment. Our initial focus is quantitative work that informs global priorities, 
especially in economics, policy, and other social sciences. We will encourage better 
research by making it easier for researchers to get feedback and credible ratings on 
their work. Our aim is to make rigorous research more impactful, and impactful 
research more rigorous.

This site hosts the [Unjournal data blog](posts.html). Our main web site,
[unjournal.org](https://www.unjournal.org), and
our [knowledge base](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space)
explain and present our vision, procedures and progress. The 'output' evaluations, 
including feedback and discussion, can be found on our 
[PubPub page](https://unjournal.pubpub.org/), and are indexed in scholarly archives.

We also have an [interactive dashboard](https://unjournal.shinyapps.io/uj-dashboard/).

This site and the dashboard present data and analysis on The Unjournal's 
pipeline and evaluation output. We use them to:

1. Keep track of what we are covering, when and how.

2. Present the quantitative evaluations in useful ways.

3. Benchmark, check, and aggregate the expert judgment of our evaluators 
   as reflected in their ratings and predictions.


We may expand this analysis further in the future, e.g., to include 

- Further analysis of the relevant research contexts (e.g., 'how many papers are 
  coming out by field')

- Connections to replications and prediction initiatives.

- Comparing and benchmarking our evaluations against 
  'traditional publication outcomes' for the evaluated work, such as journal tiers
  and citations.


This resource aims to be:

1. Dynamic: Regularly updated to reflect our progress

2. Transparent and replicable: sharing data and code to permit checking and 'forked' analyses

3. Interactive: presenting a dashboard-style interface, allowing readers to choose their analyses of interest.


20 May 2024: David Reinstein, Julia Bottesini, and David Hugh-Jones have done most of the analysis 
here and in the accompanying dashboards.


### Data dashboard {-}

::: column-body-outset

```{=html}

<iframe height="900" width="120%" frameborder="no" src="https://unjournal.shinyapps.io/uj-dashboard/"> </iframe>


```